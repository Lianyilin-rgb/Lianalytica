# Ollama 一键安装脚本使用说明

## 功能概述

本脚本提供 Ollama AI 模型的一键安装解决方案，并包含功能强大的WebUI启动器，具有以下特点：

### 安装脚本功能
- ✅ 自动检测并安装所需依赖（VC++运行时、PowerShell、curl）
- ✅ 智能选择国内/国际镜像源，提高下载成功率
- ✅ 支持 .exe 和 .zip 两种安装方式
- ✅ 自动检测显卡配置，推荐合适的模型量化级别
- ✅ 支持多种预定义模型选择
- ✅ 完善的下载重试机制（指数退避策略）
- ✅ 详细的错误处理和日志输出
- ✅ 支持全球用户的网络环境
- ✅ 增强的临时目录处理，提供多种备选目录并进行写入权限验证

### WebUI启动器功能
- ✅ 提供三种硬件版本（CPU-only、GPU-only、CPU+GPU+memory）
- ✅ 实时显示当前进行中的任务
- ✅ 支持音频、图片、代码的上传和深度分析
- ✅ 提供友好的文字对话界面
- ✅ 强大的音频处理功能（和弦分析、人声配和弦、乐器转MIDI等）
- ✅ 显示所有未安装的大模型供用户选择
- ✅ 支持关闭按钮的技术参考显示

## 系统要求

### 基本系统要求
- **操作系统**：Windows 10/11 (64位)
- **内存**：至少 4GB (推荐 8GB 以上)
- **存储空间**：至少 5GB 可用空间
- **网络**：稳定的网络连接（用于下载 Ollama 和模型）

### WebUI启动器系统要求

#### CPU-only版本
- **CPU**：支持AVX2指令集的64位处理器
- **内存**：至少 8GB (推荐 16GB 以上)

#### GPU-only版本
- **GPU**：NVIDIA GPU (支持CUDA 11.0+)
- **显存**：至少 4GB (推荐 8GB 以上)
- **内存**：至少 8GB (推荐 16GB 以上)

#### CPU+GPU+memory版本
- **CPU**：支持AVX2指令集的64位处理器
- **GPU**：NVIDIA GPU (支持CUDA 11.0+)
- **显存**：至少 4GB (推荐 8GB 以上)
- **内存**：至少 16GB (推荐 32GB 以上)

### 浏览器要求
- Chrome 80+、Firefox 75+、Edge 80+ 或 Safari 13+ 等现代浏览器

## 安装前准备

### 脚本安装前准备
1. **关闭杀毒软件**：部分杀毒软件可能会误报脚本行为
2. **管理员权限**：建议以管理员身份运行脚本
3. **网络检查**：确保网络连接正常，特别是能够访问 GitHub 或国内镜像源

### WebUI使用前准备
1. **浏览器准备**：确保安装了支持的现代浏览器（Chrome 80+、Firefox 75+等）
2. **硬件检查**：根据选择的WebUI版本，确保硬件符合要求
3. **存储空间**：确保有足够的临时存储空间（至少1GB）用于处理音频、图片等文件
4. **Ollama服务**：确保Ollama服务已正确安装并正在运行

## 完整安装步骤

### 1. 下载脚本

将 `install_ollama.bat` 文件下载到您的电脑上，建议放在容易访问的位置，如桌面或专门的安装目录。

### 2. 运行安装脚本

- **方法一**：双击 `install_ollama.bat` 文件
- **方法二**：以管理员身份打开命令提示符，导航到脚本所在目录，然后运行命令：
  ```cmd
  install_ollama.bat
  ```

### 3. 依赖检查与安装

脚本会自动检查并安装所需依赖：
- VC++ 运行时库
- PowerShell 更新
- curl（如果需要）

### 4. Ollama 安装

脚本会尝试两种安装方式：
1. 首先尝试使用官方 .exe 安装程序（更简单的安装方式）
2. 如果 .exe 安装失败，会尝试使用 .zip 文件手动安装

### 5. 显卡配置检测

脚本会自动检测您的显卡显存大小：
```
检测到显卡显存: XGB
```

### 6. 模型选择

脚本提供以下6种常用模型供选择：
1. llama3 (默认)
2. mistral
3. qwen:7b
4. gemma:7b
5. phi3:3.8b
6. codellama:7b

您可以通过输入数字选择模型，也可以直接输入其他模型名称使用自定义模型。

### 7. 模型量化级别推荐

根据您的显卡显存，脚本会推荐合适的模型量化级别：
- 4GB 以下：q4_0
- 4-8GB：q4_1
- 8-12GB：q5_0
- 12GB 以上：q5_1

您可以选择使用推荐的量化级别，或者根据需要手动选择。

### 8. 自定义模型存储路径

在安装过程中，您可以选择自定义模型存储路径：
```
正在配置模型存储路径...
默认模型存储路径：%USERPROFILE%\.ollama\models
请输入自定义模型存储路径（直接回车使用默认路径）：
```

### 9. Ollama 服务启动

脚本会自动启动 Ollama 服务：
```
正在启动Ollama服务...
```

### 10. 模型下载

脚本会自动下载您选择的模型：
```
尝试下载模型（第 1 次）...
此过程可能需要较长时间，请耐心等待...
```

### 11. 完成安装

安装完成后，脚本会显示使用说明：
```
===========================================
安装完成！
您可以通过以下命令使用Ollama：
  ollama run 模型名称
===========================================
```

## 基本使用方法

### 1. 启动 Ollama 服务

如果服务未自动启动，您可以通过以下方式启动：
```cmd
ollama serve
```

### 2. 运行模型

使用以下命令运行已安装的模型：
```cmd
ollama run 模型名称
```

例如：
```cmd
ollama run llama3
```

### 3. 退出模型会话

在模型会话中，输入 `/bye` 退出：
```
>>> /bye
```

### 4. 常用命令

- **列出本地模型**：`ollama list`
- **拉取新模型**：`ollama pull 模型名称`
- **删除模型**：`ollama rm 模型名称`
- **查看模型信息**：`ollama show 模型名称`
- **创建自定义模型**：`ollama create 自定义名称 -f modelfile.txt`
- **推送模型到仓库**：`ollama push 模型名称`
- **从仓库拉取模型**：`ollama pull 模型名称`

## 高级功能

### 1. 使用不同的模型量化版本

您可以通过指定标签来使用不同量化级别的模型：
```cmd
ollama run llama3:q4_0  # 较低精度，较小占用空间
ollama run llama3:q5_1  # 较高精度，较大占用空间
```

### 2. 创建自定义模型

您可以创建基于现有模型的自定义模型：
1. 创建一个 `modelfile.txt` 文件
2. 定义模型配置
3. 使用 `ollama create` 命令构建

示例 modelfile.txt：
```
FROM llama3
PARAMETER temperature 0.7
SYSTEM "你是一个专业的编程助手"
```

构建命令：
```cmd
ollama create my-code-assistant -f modelfile.txt
```

### 3. 使用模型进行对话

运行模型后，您可以直接与其进行对话：
```
>>> 你好，如何学习Python编程？

学习Python编程可以分为以下几个步骤：
1. 安装Python环境
2. 学习基本语法
3. 实践简单项目
4. 学习高级特性
5. 参与开源项目
```

### 4. 使用模型生成代码

您可以要求模型生成代码：
```
>>> 写一个Python函数来计算斐波那契数列

def fibonacci(n):
    if n <= 0:
        return []
    elif n == 1:
        return [0]
    elif n == 2:
        return [0, 1]
    else:
        fib = [0, 1]
        for i in range(2, n):
            fib.append(fib[i-1] + fib[i-2])
        return fib
```

## 常见问题与解决方法

### 1. 下载失败

**问题**：所有镜像源都无法下载 Ollama 或模型

**解决方法**：
- 检查网络连接是否正常
- 确保防火墙允许脚本访问网络
- 尝试手动设置代理
- 重启路由器或更换网络环境

### 2. 临时目录权限问题

**问题**：脚本提示无法写入临时目录

**解决方法**：
- 确保您有足够的权限运行脚本
- 尝试以管理员身份运行
- 脚本会自动尝试使用以下目录（按优先级）：
  1. 用户下载目录：`%USERPROFILE%\Downloads\ollama_temp`
  2. 用户文档目录：`%USERPROFILE%\Documents\ollama_temp`
  3. 当前工作目录：脚本运行的目录
  4. 脚本所在目录：脚本文件存放的目录
  5. 系统临时目录：`%TEMP%\ollama_temp`
  6. 用户桌面目录：`%USERPROFILE%\Desktop\ollama_temp`
  7. 用户主目录：`%USERPROFILE%\ollama_temp`
- 如果所有目录都无法写入，尝试手动在任意可写位置创建 `ollama_temp` 目录，并将脚本放置该目录中运行

### 3. 模型下载超时

**问题**：模型下载过程中超时

**解决方法**：
- 检查网络稳定性
- 尝试较小的模型或较低的量化级别
- 手动下载模型文件并放置到模型目录
- 增加下载超时时间（需要修改脚本）

### 4. Ollama 命令不识别

**问题**：命令提示符中输入 `ollama` 提示找不到命令

**解决方法**：
- 重启命令提示符窗口
- 手动将 Ollama 安装目录添加到系统 PATH 环境变量
- 重新运行安装脚本

### 5. 模型运行时内存不足

**问题**：运行模型时提示内存不足

**解决方法**：
- 关闭其他占用内存的程序
- 使用更低量化级别的模型（如 q4_0）
- 增加系统内存

### 6. 杀毒软件误报

**问题**：杀毒软件提示脚本有风险

**解决方法**：
- 关闭杀毒软件后重新运行
- 将脚本添加到杀毒软件的白名单
- 手动下载 Ollama 并安装

## 错误代码说明

| 错误代码 | 说明 | 解决方法 |
|---------|------|---------|
| 1 | 依赖安装失败 | 检查网络连接，手动安装缺失的依赖 |
| 2 | Ollama 下载失败 | 检查网络连接，尝试更换网络环境 |
| 3 | Ollama 解压失败 | 重新下载安装包，确保下载完整 |
| 4 | 模型下载失败 | 尝试较小的模型，检查网络稳定性 |
| 5 | 临时目录权限问题 | 以管理员身份运行，检查目录权限 |

## 技术细节

### 镜像源配置

脚本会自动检测您的地区（通过IP地址）并选择最佳镜像源：

#### 国内用户 (中国地区)
使用以下镜像源（按优先级排序）：
- https://cdn.jsdelivr.net (国内CDN)
- https://gh.api.99988866.xyz (GitHub镜像)
- https://fastly.jsdelivr.net (CDN)
- https://mirror.ghproxy.com (GitHub镜像)
- https://gcore.jsdelivr.net (CDN)
- GitHub官方源 (备用)

#### 国际用户
使用以下镜像源（按优先级排序）：
- GitHub官方源
- https://cdn.jsdelivr.net
- https://fastly.jsdelivr.net

### 重试机制

- 下载失败时，会自动重试最多 3 次
- 重试间隔采用指数退避策略：3秒 → 6秒 → 12秒
- 支持从不同镜像源进行重试
- 同时支持两种下载工具：
  - `curl.exe`（优先）- 直接调用系统或内置的curl命令
  - PowerShell `Invoke-WebRequest`（备用）- 当curl失败时自动切换

### 临时目录处理

为了避免权限问题，脚本采用多层目录回退策略，会自动尝试以下目录（按优先级）：

1. **用户下载目录**：`%USERPROFILE%\Downloads\ollama_temp`
2. **用户文档目录**：`%USERPROFILE%\Documents\ollama_temp`
3. **当前工作目录**：脚本运行的目录
4. **脚本所在目录**：脚本文件存放的目录
5. **系统临时目录**：`%TEMP%\ollama_temp`
6. **用户桌面目录**：`%USERPROFILE%\Desktop\ollama_temp`
7. **用户主目录**：`%USERPROFILE%\ollama_temp`

**写入权限验证机制**：
- 对每个备选目录，脚本会先尝试创建目录
- 然后通过在目录中创建一个测试文件（`test.txt`）来验证写入权限
- 如果验证成功，使用该目录作为下载目录
- 成功后自动删除测试文件
- 如果所有目录都无法写入，脚本会显示错误信息并退出

### 模型存储路径

- 默认模型存储路径：`%USERPROFILE%\.ollama\models`
- 支持自定义模型存储路径
- 建议将模型存储在有足够空间的硬盘上

## 使用教学

### 教学1：基本对话

1. 安装完成后，运行命令：
   ```cmd
   ollama run llama3
   ```

2. 与模型进行对话：
   ```
   >>> 你好，我叫连毅霖
   你好，连毅霖！很高兴认识你。今天有什么我可以帮助你的吗？
   
   >>> 介绍一下自己
   我是Llama 3，一个由Meta开发的大型语言模型。我可以帮助你回答问题、提供信息、进行对话，甚至帮助你创作内容。有什么我可以为你做的吗？
   
   >>> /bye
   ```

### 教学2：代码生成

1. 运行命令：
   ```cmd
   ollama run codellama:7b
   ```

2. 请求生成代码：
   ```
   >>> 写一个Python函数来计算阶乘
   以下是一个计算阶乘的Python函数：
   
   def factorial(n):
       """计算n的阶乘"""
       if n == 0 or n == 1:
           return 1
       else:
           return n * factorial(n-1)
   
   # 示例使用
   print(factorial(5))  # 输出: 120
   
   >>> 解释一下这段代码
   这段代码定义了一个名为factorial的函数，用于计算一个整数的阶乘。
   
   1. 函数定义: `def factorial(n):` - 定义了一个名为factorial的函数，接受一个参数n
   2. 文档字符串: `"""计算n的阶乘"""` - 描述了函数的功能
   3. 基本情况: `if n == 0 or n == 1: return 1` - 当n为0或1时，阶乘为1
   4. 递归情况: `else: return n * factorial(n-1)` - 当n大于1时，阶乘为n乘以n-1的阶乘
   5. 示例使用: `print(factorial(5))` - 计算5的阶乘并打印结果
   ```

### 教学3：知识问答

1. 运行命令：
   ```cmd
   ollama run llama3
   ```

2. 提问：
   ```
   >>> 什么是人工智能？
   人工智能（Artificial Intelligence，简称AI）是计算机科学的一个分支，旨在创造能够模拟人类智能的机器或系统。人工智能的目标包括让计算机能够理解自然语言、学习、推理、解决问题、感知环境和进行决策。
   
   >>> 人工智能有哪些应用领域？
   人工智能的应用领域非常广泛，包括但不限于：
   1. 自然语言处理：聊天机器人、语音助手、机器翻译
   2. 计算机视觉：图像识别、人脸识别、自动驾驶
   3. 推荐系统：电商推荐、内容推荐
   4. 医疗健康：疾病诊断、药物研发
   5. 金融服务：欺诈检测、算法交易
   6. 教育：个性化学习、智能辅导
   7. 制造业：智能制造、预测性维护
   ```

### 教学4：创建自定义模型

1. 创建一个 `modelfile.txt` 文件，内容如下：
   ```
   FROM llama3
   PARAMETER temperature 0.7
   SYSTEM "你是一个专业的编程助手，回答要简洁明了。"
   ```

2. 运行命令创建自定义模型：
   ```cmd
   ollama create my-code-assistant -f modelfile.txt
   ```

3. 运行自定义模型：
   ```cmd
   ollama run my-code-assistant
   ```

4. 测试自定义模型：
   ```
   >>> 写一个快速排序算法
   ```

## 配置说明

### 1. 基本配置

编辑 `config.json` 文件来自定义 WebUI 和 Ollama 配置：

```json
{
  "server": {
    "port": 8001,              # WebUI 服务端口
    "host": "0.0.0.0",         # WebUI 服务主机
    "debug": false             # 启用调试模式
  },
  "ollama": {
    "url": "http://localhost:11434",  # Ollama 服务地址
    "timeout": 300,               # 请求超时时间（秒）
    "model": "llama3"           # 默认使用的模型
  },
  "tasks": {
    "max_concurrent": 5,          # 最大并发任务数
    "temp_dir": "temp",         # 临时文件目录
    "cleanup_interval": 3600      # 清理临时文件的间隔（秒）
  },
  "audio": {
    "max_file_size": 100,         # 最大音频文件大小（MB）
    "supported_formats": ["mp3", "wav", "flac", "ogg"],  # 支持的音频格式
    "analysis_precision": "high"  # 分析精度（高/中/低）
  },
  "image": {
    "max_file_size": 50,          # 最大图像文件大小（MB）
    "supported_formats": ["jpg", "png", "gif"]  # 支持的图像格式
  },
  "code": {
    "max_file_size": 10,          # 最大代码文件大小（MB）
    "supported_languages": ["python", "javascript", "java", "cpp"]  # 支持的编程语言
  }
}
```

### 2. 高级配置

#### 2.1 服务器配置
- **`port`**: WebUI 服务端口，默认值为 8001
- **`host`**: WebUI 服务主机，`0.0.0.0` 表示可从所有网络接口访问
- **`debug`**: 启用开发调试模式，默认值为 false

#### 2.2 Ollama 配置
- **`url`**: Ollama 服务地址，默认值为 `http://localhost:11434`
- **`timeout`**: Ollama 服务请求超时时间，默认值为 300 秒
- **`model`**: 用于处理的默认模型，默认值为 "llama3"

#### 2.3 任务配置
- **`max_concurrent`**: 最大并发任务数，根据系统性能进行调整
- **`temp_dir`**: 存储临时文件的目录，默认值为 "temp"
- **`cleanup_interval`**: 自动清理临时文件的间隔，默认值为 3600 秒

#### 2.4 音频配置
- **`max_file_size`**: 最大音频文件大小（MB），默认值为 100 MB
- **`supported_formats`**: 支持的音频格式列表
- **`analysis_precision`**: 分析精度级别，影响处理准确性和速度

#### 2.5 图像配置
- **`max_file_size`**: 最大图像文件大小（MB），默认值为 50 MB
- **`supported_formats`**: 支持的图像格式列表

#### 2.6 代码配置
- **`max_file_size`**: 最大代码文件大小（MB），默认值为 10 MB
- **`supported_languages`**: 支持的编程语言列表

### 3. 配置技巧

1. **性能优化**:
   - 对于低配置系统，将 `max_concurrent` 减少到 2-3
   - 对于高配置系统，将 `max_concurrent` 增加到 8-10
   - 根据模型大小和复杂度调整 `timeout`

2. **安全设置**:
   - 将 `host` 更改为 "127.0.0.1" 以仅限制本地访问
   - 设置适当的 `max_file_size` 限制以防止滥用
   - 定期检查和清理 `temp_dir`

3. **自定义建议**:
   - 在相应部分添加或删除支持的格式
   - 根据您的需求更改默认模型
   - 根据质量要求调整音频处理的 `analysis_precision`

## WebUI启动器使用说明

### 功能概述

WebUI启动器是一个功能强大的图形化界面工具，基于Flask框架开发，方便用户使用Ollama的各种功能，包括：
- ✅ 支持三种硬件版本（CPU-only、GPU-only、CPU+GPU+memory）
- ✅ 实时显示当前进行中的任务
- ✅ 支持音频、图片、代码的上传和深度分析
- ✅ 提供友好的文字对话界面
- ✅ 显示所有未安装的大模型供用户选择
- ✅ 支持关闭按钮的技术参考显示
- ✅ RESTful API设计，便于扩展和集成
- ✅ 线程安全的任务管理系统

### 启动器版本说明

我们提供三种不同硬件支持的启动器版本，所有版本功能完全一致，但针对不同硬件环境进行了优化：

#### 1. **OllamaWebUI_CPU.exe**
- **硬件要求**：支持AVX2指令集的64位处理器，至少8GB内存
- **工作原理**：完全使用CPU和内存运行，不依赖GPU
- **适用场景**：没有独立显卡的用户，或需要在低功耗环境下使用
- **性能特点**：资源占用较低，但处理速度相对较慢
- **最佳使用**：适合文本对话、代码分析等轻量级任务

#### 2. **OllamaWebUI_GPU.exe**
- **硬件要求**：NVIDIA GPU（支持CUDA 11.0+），至少4GB显存，8GB内存
- **工作原理**：优先使用GPU进行计算，充分利用显卡性能
- **适用场景**：有独立显卡的用户，需要处理大量数据或复杂任务
- **性能特点**：处理速度快，但对显卡性能要求较高
- **最佳使用**：适合音频处理、图片分析等计算密集型任务

#### 3. **OllamaWebUI_GPU_MEM.exe**
- **硬件要求**：支持AVX2的CPU，NVIDIA GPU（CUDA 11.0+），8GB显存，16GB内存
- **工作原理**：同时使用CPU、GPU和内存，智能分配计算资源
- **适用场景**：需要平衡性能和稳定性的用户，或处理多样化任务
- **性能特点**：资源利用最充分，处理速度快，稳定性好
- **最佳使用**：适合同时进行多种任务或处理大型文件

### 启动器的获取和安装

#### 方式一：从发布页面下载
1. 访问项目的GitHub发布页面或官方网站
2. 根据您的硬件配置选择合适的版本
3. 下载对应的EXE文件到本地目录

#### 方式二：自行编译
如果您需要自定义启动器，可以自行编译：
1. 确保已安装Python 3.10+
2. 克隆项目仓库
3. 安装依赖：`pip install -r requirements.txt`
4. 使用PyInstaller打包：
   ```cmd
   pyinstaller --onefile --windowed --add-data "index.html;." --add-data "user.css;." --add-data "config.json;." main.py
   ```

### WebUI界面操作指南

#### 主界面功能

- **服务状态**：显示Ollama服务的运行状态
- **启动/停止按钮**：控制Ollama服务的运行
- **模型管理**：查看和管理已安装的模型
- **功能标签页**：
  - **对话**：与大模型进行聊天
  - **音频处理**：和弦分析、人声配和弦等
  - **图像处理**：图像生成、分析等
  - **代码处理**：代码理解、优化建议等
  - **设置**：配置WebUI和Ollama参数

#### WebUI界面布局和组件

WebUI界面采用直观的标签页布局，主要由以下组件组成：

##### 顶部导航栏
- **Logo和标题**：显示WebUI的名称和版本
- **标签页**：包含"音频处理"、"图像处理"、"代码处理"和"对话"四个主要功能模块
- **设置按钮**：用于配置WebUI参数和选项
- **帮助按钮**：提供使用帮助和技术支持信息

##### 左侧功能区
- **模型选择**：显示已安装的模型，支持搜索和筛选
- **处理类型选择**：根据功能模块显示不同的处理选项
- **上传区域**：支持拖放文件或点击选择文件
- **参数设置**：根据处理类型显示相关参数
- **操作按钮**：执行处理、发送等操作

##### 右侧结果区
- **任务列表**：实时显示当前正在进行的任务
- **结果显示**：显示处理后的结果，支持文本、表格、图表等格式
- **下载按钮**：用于下载处理后的文件（如MIDI文件、分离的音频等）
- **参考资料**：显示相关技术资料和论文引用

##### 底部状态栏
- **连接状态**：显示与Ollama服务的连接状态
- **系统资源**：显示CPU、GPU和内存使用情况
- **版本信息**：显示WebUI的版本号

#### 快捷键

| 快捷键 | 功能 |
|--------|------|
| `Ctrl+Enter` | 提交请求 |
| `Ctrl+1` | 切换到对话标签页 |
| `Ctrl+2` | 切换到音频处理标签页 |
| `Ctrl+3` | 切换到图像处理标签页 |
| `Ctrl+4` | 切换到代码处理标签页 |
| `Ctrl+5` | 切换到设置标签页 |

#### 启动器的工作原理

WebUI启动器的工作原理如下：

##### 启动流程
- 当启动器启动时，首先检查系统环境和依赖
- 初始化Flask服务器
- 连接到本地Ollama服务
- 启动Web界面

##### 文件处理流程
- 用户上传文件后，文件临时存储在`temp`目录中
- 启动器将文件路径和处理参数发送给Ollama服务
- Ollama调用相应的模型进行处理
- 处理结果返回给WebUI并显示给用户
- 处理完成后，临时文件会自动清理

##### 任务管理
- 使用`active_tasks`列表存储当前任务
- 使用`tasks_lock`（threading.Lock）确保线程安全
- 通过`add_task`、`update_task`、`get_active_tasks`等函数管理任务
- 支持并发处理多个任务

#### 启动器的文件结构

启动器运行时会创建以下文件和目录：

```
OllamaWebUI_CPU.exe
├── config.json        # 配置文件
├── temp/             # 临时文件目录
│   ├── audio/        # 音频临时文件
│   ├── image/        # 图像临时文件
│   └── code/         # 代码临时文件
├── logs/             # 日志目录
│   └── webui.log     # WebUI日志
└── index.html        # Web界面文件（嵌入在EXE中）
```

#### 键盘快捷键

##### 通用快捷键

| 快捷键 | 功能 |
|--------|------|
| `Ctrl+Enter` | 提交请求/开始处理 |
| `Ctrl+K` | 清空输入框 |
| `Ctrl+L` | 切换语言 |
| `Ctrl+Shift+M` | 打开模型选择面板 |
| `Esc` | 关闭当前弹出窗口 |

##### 音频处理快捷键

| 快捷键 | 功能 |
|--------|------|
| `Ctrl+1` | 选择和弦分析 |
| `Ctrl+2` | 选择人声配和弦 |
| `Ctrl+3` | 选择乐器转MIDI |
| `Ctrl+4` | 选择乐器分离 |

##### 图像处理快捷键

| 快捷键 | 功能 |
|--------|------|
| `Ctrl+O` | 打开图像文件 |
| `Ctrl+S` | 保存分析结果 |
| `Ctrl+R` | 刷新预览 |

##### 代码处理快捷键

| 快捷键 | 功能 |
|--------|------|
| `Ctrl+A` | 全选代码 |
| `Ctrl+F` | 搜索代码 |
| `Ctrl+/` | 注释/取消注释代码 |

#### 界面个性化设置

1. **主题切换**：
   - 点击右上角的"设置"按钮
   - 在"外观"选项中选择"浅色"或"深色"主题

2. **字体大小调整**：
   - 在"设置"面板中选择"字体大小"
   - 调整为"小"、"中"、"大"或自定义值

3. **语言设置**：
   - 在"设置"面板中选择"语言"
   - 支持中文、英文、日文等多种语言

4. **快捷键自定义**：
   - 在"设置"面板中选择"快捷键"
   - 点击功能对应的快捷键组合进行修改

### EXE文件详细说明

#### 什么是EXE文件？
WebUI启动器EXE文件是一种独立的Windows可执行文件，将Python Flask应用程序、所有依赖库和静态资源打包成单个文件，用户无需安装任何额外软件即可直接运行。

#### 技术实现原理

1. **打包技术细节**：
   - 使用PyInstaller 6.0+进行打包，支持Windows 10/11系统
   - 核心命令示例：
     ```cmd
     pyinstaller --onefile --windowed --add-data "index.html;app/templates" --add-data "user.css;app/static/css" --add-data "config.json;app/config" --icon "app.ico" main.py
     ```
   - 通过`--windowed`参数隐藏命令行窗口，提供更友好的用户体验
   - 使用自定义图标增强品牌识别度

2. **文件结构解析**：
   - 核心可执行代码：Python解释器、Flask框架、业务逻辑
   - 静态资源：HTML界面、CSS样式、JavaScript交互代码
   - 配置文件：默认配置模板、模型列表、功能参数
   - 依赖库：numpy、librosa、music21、requests等

3. **启动流程详解**：
   - **阶段1：初始化**（0-3秒）
     - 系统加载EXE文件到内存
     - 解压嵌入式资源到临时目录（%TEMP%\_MEIxxxxxx）
     - 初始化Python解释器环境
   - **阶段2：服务启动**（3-10秒）
     - 加载并初始化所有依赖库
     - 启动Flask服务器和线程池
     - 验证与Ollama服务的连接
   - **阶段3：界面准备**（10-15秒）
     - 启动内置Web服务器（默认端口8001）
     - 自动检测并打开默认浏览器
     - 加载WebUI界面和资源
   - **阶段4：运行就绪**
     - 显示"WebUI启动成功"提示
     - 等待用户操作和请求

#### 不同版本的优化特点

| 版本名称 | 硬件要求 | 核心优化 | 适用场景 |
|----------|----------|----------|----------|
| OllamaWebUI_CPU.exe | 无独立显卡 | CPU性能优化<br>内存占用控制<br>启动速度优化 | 办公电脑<br>轻薄本<br>旧款电脑 |
| OllamaWebUI_GPU.exe | NVIDIA GPU (CUDA 11.0+) | GPU加速计算<br>并行任务处理<br>显存优化 | 游戏本<br>设计工作站<br>有独立显卡的电脑 |
| OllamaWebUI_GPU_MEM.exe | NVIDIA GPU + 16GB+内存 | 内存缓存优化<br>大模型支持<br>多任务并发 | 高端游戏本<br>专业工作站<br>服务器级配置 |

#### 与Python脚本的全面对比

| 特性 | EXE文件 | Python脚本 |
|------|---------|------------|
| **依赖要求** | 无需安装任何软件 | 需要Python 3.10+、pip、所有依赖库 |
| **部署难度** | ★☆☆☆☆（双击即运行） | ★★★★☆（需要配置环境） |
| **启动速度** | 首次：10-15秒<br>后续：5-8秒 | 3-5秒 |
| **磁盘占用** | 单个文件：150-200MB | 约50MB（不含Python） |
| **资源消耗** | CPU：5-15%<br>内存：500MB-1.5GB | CPU：3-10%<br>内存：300MB-1GB |
| **安全性** | 数字签名验证<br>防篡改保护 | 直接执行源代码<br>安全性依赖环境 |
| **跨平台** | 仅限Windows 10/11 | 支持Windows/macOS/Linux |
| **自定义性** | 有限（通过配置文件） | 高度可定制 |
| **稳定性** | 高（环境隔离） | 依赖系统环境 |

#### 安全性与隐私保护

1. **数字签名保障**：
   - 所有官方发布的EXE文件均由我们的数字证书签名
   - 验证方法：右键点击EXE文件 → 属性 → 数字签名 → 查看签名者信息
   - 签名确保文件未被第三方篡改或植入恶意代码

2. **防病毒软件兼容**：
   - 定期向主流杀毒软件厂商提交文件样本进行白名单认证
   - 若遇到误报，请将EXE文件添加到杀毒软件白名单
   - 建议从官方GitHub仓库或官网下载，避免从第三方来源获取

3. **隐私数据保护**：
   - 所有数据处理均在本地进行，不会上传到任何云端服务器
   - 临时文件存储在用户目录的临时文件夹中
   - 处理完成后自动清理所有临时数据
   - 不收集任何用户个人信息或使用数据

4. **权限管理**：
   - 默认仅需要普通用户权限即可运行
   - 写入操作仅针对临时目录和用户可写的配置文件
   - 不会修改系统文件或注册表

#### EXE文件使用技巧

1. **快捷启动设置**：
   - 右键点击EXE文件 → 发送到 → 桌面快捷方式
   - 右键点击快捷方式 → 属性 → 目标栏，可以添加启动参数
   - 例如：`"C:\Users\用户名\Desktop\OllamaWebUI_GPU.exe" --port 8080`

2. **资源占用优化**：
   - 关闭不需要的功能模块可减少内存占用
   - 对于低配置电脑，建议使用CPU版本并关闭后台程序
   - 调整`config.json`中的`max_concurrent`参数控制并发任务数

3. **启动参数高级用法**：
   ```cmd
   # 自定义端口和Ollama地址
   OllamaWebUI_GPU.exe --port 9000 --ollama-url http://192.168.1.100:11434
   
   # 启用详细日志和调试模式
   OllamaWebUI_CPU.exe --debug --log-level debug
   
   # 使用自定义配置文件
   OllamaWebUI_GPU_MEM.exe --config "D:\MyConfig\custom_config.json"
   
   # 禁用自动打开浏览器
   OllamaWebUI_GPU.exe --no-browser
   ```

#### 常见问题与解决方案

1. **问题**：EXE文件下载后无法运行
   **解决方案**：
   - 检查文件完整性（对比SHA256哈希值）
   - 关闭杀毒软件或添加到白名单
   - 以管理员身份运行
   - 确保Windows版本在10以上

2. **问题**：首次启动时间过长
   **解决方案**：
   - 首次启动需要解压所有资源，属于正常现象
   - 后续启动会显著加快（5-8秒）
   - 确保系统磁盘空间充足（至少1GB空闲）

3. **问题**：EXE文件被杀毒软件误报
   **解决方案**：
   - 将文件添加到杀毒软件白名单
   - 从官方渠道重新下载
   - 暂时关闭实时保护后运行
   - 提交误报样本给杀毒软件厂商

4. **问题**：临时目录占用过大
   **解决方案**：
   - 程序结束后会自动清理临时文件
   - 若异常退出，可手动删除%TEMP%目录下的_MEIxxxxxx文件夹
   - 在配置文件中自定义临时目录位置

#### 高级自定义与扩展

1. **手动修改配置**：
   - 运行一次EXE文件后，会在同目录生成`config.json`文件
   - 可以直接编辑该文件修改端口、Ollama地址、并发数等参数
   - 修改后需要重启EXE文件生效

2. **提取和修改资源**：
   - 使用PyInstaller Extractor工具可以提取EXE中的资源文件
   - 自定义HTML界面、CSS样式和配置文件
   - 修改后需要重新打包生成新的EXE文件

3. **集成到其他程序**：
   - EXE文件支持命令行调用，可以集成到其他应用程序中
   - 可以通过API接口与其他系统进行交互
   - 支持静默启动和关闭

### 启动WebUI

#### 基本启动
1. 确保您已安装Ollama（可使用本脚本安装）
2. 确保Ollama服务正在运行（可通过`ollama serve`命令启动）
3. 根据您的硬件配置选择合适的启动器版本
4. 双击运行启动器EXE文件
5. 启动器会自动在后台运行，并在系统托盘中显示图标
6. 默认情况下，浏览器会自动打开WebUI界面（http://localhost:8001）

#### 高级启动参数
启动器支持以下命令行参数：

```cmd
# 指定端口号
OllamaWebUI_CPU.exe --port 8080

# 指定Ollama服务地址
OllamaWebUI_CPU.exe --ollama-url http://localhost:11434

# 启用调试模式
OllamaWebUI_CPU.exe --debug

# 指定配置文件
OllamaWebUI_CPU.exe --config config.json
```

### WebUI界面布局和组件说明

WebUI界面采用直观的选项卡布局，主要包含以下组件：

#### 1. 顶部导航栏
- **Logo和标题**：显示WebUI的名称和版本
- **选项卡**：包含"音频处理"、"图片处理"、"代码处理"、"对话"四个主要功能模块
- **设置按钮**：用于配置WebUI的参数和选项
- **帮助按钮**：提供使用帮助和技术支持信息

#### 2. 左侧功能区
- **模型选择**：显示已安装的模型，支持搜索和筛选
- **处理类型选择**：根据功能模块显示不同的处理选项
- **上传区域**：支持拖放文件或点击选择文件
- **参数设置**：根据处理类型显示相关参数
- **操作按钮**：执行处理、发送等操作

#### 3. 右侧结果区
- **任务列表**：实时显示当前进行中的任务
- **结果显示**：显示处理后的结果，支持文本、表格、图表等格式
- **下载按钮**：用于下载处理后的文件（如MIDI文件、分离后的音频等）
- **参考资料**：显示相关的技术资料和论文引用

#### 4. 底部状态栏
- **连接状态**：显示与Ollama服务的连接状态
- **系统资源**：显示CPU、GPU、内存的使用情况
- **版本信息**：显示WebUI的版本号

### 启动器的工作原理

WebUI启动器的工作原理如下：

1. **启动流程**：
   - 启动器启动时，首先检查系统环境和依赖
   - 初始化Flask服务器
   - 连接到本地Ollama服务
   - 启动Web界面

2. **文件处理流程**：
   - 用户上传文件后，文件被临时存储在`temp`目录
   - 启动器将文件路径和处理参数发送给Ollama服务
   - Ollama调用相应的模型进行处理
   - 处理结果返回给WebUI并显示给用户
   - 处理完成后，临时文件自动清理

3. **任务管理**：
   - 使用`active_tasks`列表存储当前任务
   - 使用`tasks_lock`（threading.Lock）确保线程安全
   - 通过`add_task`、`update_task`、`get_active_tasks`等函数管理任务
   - 支持多任务并发处理

### 启动器的高级配置

启动器支持通过配置文件进行高级设置，配置文件为`config.json`，与启动器EXE文件放在同一目录：

```json
{
  "server": {
    "port": 8001,
    "host": "0.0.0.0",
    "debug": false
  },
  "ollama": {
    "url": "http://localhost:11434",
    "timeout": 300
  },
  "tasks": {
    "max_concurrent": 5,
    "temp_dir": "temp"
  },
  "audio": {
    "max_file_size": 100,
    "supported_formats": ["mp3", "wav", "flac"]
  },
  "image": {
    "max_file_size": 50,
    "supported_formats": ["jpg", "png", "gif"]
  }
}
```

### 启动器的文件结构

启动器运行时会创建以下文件和目录：

```
OllamaWebUI_CPU.exe
├── config.json        # 配置文件
├── temp/             # 临时文件目录
│   ├── audio/        # 音频临时文件
│   ├── image/        # 图片临时文件
│   └── code/         # 代码临时文件
├── logs/             # 日志目录
│   └── webui.log     # WebUI日志
└── index.html        # Web界面文件（嵌入在EXE中）
```

### WebUI功能介绍

#### 1. 音频处理功能

WebUI提供强大的音频处理能力，支持以下功能：

##### 和弦分析
1. 点击"音频处理"选项卡
2. 选择合适的模型（推荐使用音乐理论增强模型）
3. 在"处理类型"中选择"和弦分析"
4. 上传音频文件（支持.mp3/.wav格式）
5. 点击"处理音频"按钮
6. 在任务列表中查看实时进度
7. 处理完成后，查看和弦进行、调性、和声结构等分析结果

##### 人声配和弦
1. 点击"音频处理"选项卡
2. 选择合适的模型
3. 在"处理类型"中选择"人声配和弦"
4. 上传人声音频文件
5. 点击"处理音频"按钮
6. 等待处理完成后，查看生成的和弦伴奏（支持流行、摇滚、爵士等多种风格）

##### 乐器转MIDI
1. 点击"音频处理"选项卡
2. 选择合适的模型
3. 在"处理类型"中选择"乐器转MIDI"
4. 上传乐器音频文件
5. 点击"处理音频"按钮
6. 处理完成后，下载生成的MIDI文件，可用于DAW软件进行进一步编辑

##### 乐器分离
1. 点击"音频处理"选项卡
2. 在"处理类型"中选择"乐器分离"
3. 上传音频文件
4. 选择需要分离的乐器（音乐、人声、鼓、Bass、吉他等）
5. 点击"处理音频"按钮
6. 处理完成后，下载分离后的各轨音频文件

## 用户场景教程

### 1. 音乐创作者场景

#### 适用场景
适合音乐制作人、作曲家、编曲家、歌手等音乐专业人士使用WebUI进行音乐创作辅助、音频分析、MIDI制作和歌曲重新编曲。

#### 所需准备
1. **硬件要求**：推荐使用GPU版本启动器（OllamaWebUI_GPU.exe），需配备NVIDIA GPU（CUDA 11.0+）
2. **音频文件**：准备好用于分析或处理的音频文件（支持.mp3/.wav/.flac格式，推荐44.1kHz采样率）
3. **DAW软件**：建议安装DAW软件（如Cubase、FL Studio、Logic Pro、Ableton Live）用于后续编辑
4. **存储空间**：建议预留至少5GB存储空间用于临时文件处理

#### 保姆级完整工作流

### 第一步：启动WebUI（30秒完成）

1. **选择合适的启动器**：
   - 如果您的电脑有NVIDIA显卡（GTX 1660及以上）：使用`OllamaWebUI_GPU.exe`
   - 如果您的电脑没有GPU：使用`OllamaWebUI_CPU.exe`
   - 如果您的电脑配置较高（8GB+内存+高端GPU）：使用`OllamaWebUI_GPU_MEM.exe`

2. **运行启动器**：
   - 双击下载的启动器文件（无需安装，绿色软件）
   - 首次运行可能会被杀毒软件拦截，点击"允许"或"信任"

3. **访问界面**：
   - 启动后，浏览器会自动打开，显示WebUI主界面
   - 如果未自动打开，手动访问：`http://localhost:8001`

### 第二步：人声配和弦（10分钟掌握）

这是音乐创作者最常用的功能，可以为您的人声自动生成和谐的和弦进行。

```
详细步骤：
1. 点击顶部的"音频处理"选项卡
2. 在"处理类型"下拉菜单中选择"人声配和弦"
3. 点击"选择文件"按钮，上传您的人声音频文件（推荐1-3分钟的清唱片段）
4. 在"风格选择"中选择合适的风格：
   - 流行：适合现代流行歌曲
   - 爵士：适合复杂和声的爵士风格
   - 古典：适合优雅的古典音乐风格
   - 摇滚：适合有力量感的摇滚风格
5. 在"伴奏类型"中选择您想要的伴奏乐器：
   - 钢琴：优雅的钢琴伴奏
   - 吉他：温暖的吉他伴奏
   - 乐队：完整的乐队伴奏
6. 点击"处理音频"按钮，等待处理完成

预期结果：
- 为您的人声自动生成和谐的和弦进行
- 提供多种和弦进行变体供选择
- 支持试听不同风格的伴奏
- 可下载MIDI格式的和弦文件，直接导入DAW使用
```

### 第三步：乐器转MIDI（15分钟精通）

将真实乐器演奏转换为MIDI格式，方便在DAW中进行编辑和修改。

```
详细步骤：
1. 点击顶部的"音频处理"选项卡
2. 在"处理类型"下拉菜单中选择"乐器转MIDI"
3. 点击"选择文件"按钮，上传您的乐器独奏音频（如吉他独奏、钢琴演奏）
4. 在"乐器类型"中选择乐器类型：
   - 吉他：处理吉他演奏
   - 钢琴：处理钢琴演奏
   - 弦乐：处理小提琴等弦乐器
   - 其他：处理其他乐器
5. 在"精度设置"中选择：
   - 低：处理速度快，适合简单旋律
   - 中：速度和精度的平衡
   - 高：最高精度，适合复杂演奏（处理时间较长）
6. 点击"处理音频"按钮，等待处理完成

预期结果：
- 将真实乐器演奏转换为精确的MIDI音符
- 保留原始演奏的动态和表情
- 自动识别音符起始时间和时长
- 为复杂录音提供音轨分离建议
- 可下载MIDI文件，直接导入DAW进行编辑
```

### 第四步：和弦分析（5分钟入门）

分析现有歌曲的和弦进行，学习优秀作品的和声结构。

```
详细步骤：
1. 点击顶部的"音频处理"选项卡
2. 在"处理类型"下拉菜单中选择"和弦分析"
3. 点击"选择文件"按钮，上传您想要分析的歌曲
4. 在"分析深度"中选择：
   - 基础：只分析主和弦
   - 高级：分析和弦转位和扩展和弦
5. 点击"处理音频"按钮，等待处理完成

预期结果：
- 生成完整的和弦进行图谱
- 按小节显示和弦名称（如Cmaj7、Am7）
- 识别歌曲调式和拍号
- 可下载PDF和弦谱用于学习
```

### 第五步：乐器分离（20分钟专业应用）

将完整歌曲分离为独立的乐器音轨，用于重新混音或采样。

```
详细步骤：
1. 点击顶部的"音频处理"选项卡
2. 在"处理类型"下拉菜单中选择"乐器分离"
3. 点击"选择文件"按钮，上传您想要分离的完整歌曲
4. 在"分离选项"中选择您需要的音轨：
   - 人声
   - 鼓
   - 贝斯
   - 吉他
   - 钢琴
   - 其他乐器
5. 点击"处理音频"按钮，等待处理完成（大文件可能需要较长时间）

预期结果：
- 生成多个独立的音频音轨文件
- 每个音轨保持原始音质和细节
- 支持单独下载每个音轨
- 可用于重新混音、混音或采样
```

### 第六步：结果应用（DAW集成）

将WebUI生成的结果导入到DAW软件中进行后续编辑：

1. **导入MIDI文件**：
   - 打开您的DAW软件（如FL Studio）
   - 选择"文件" → "导入" → "MIDI文件"
   - 选择从WebUI下载的MIDI文件
   - 为MIDI轨道分配合适的音色

2. **使用分离的音频**：
   - 将分离的音频轨道导入到DAW中
   - 重新调整各轨道的音量平衡
   - 添加效果（混响、压缩、均衡器等）

3. **完成创作**：
   - 根据需要修改和弦进行或旋律
   - 添加其他乐器轨道丰富编曲
   - 导出最终的音频文件

#### 音乐创作者高级技巧

1. **提高和弦分析准确性**：
   - 对于复杂音乐，先进行乐器分离，然后单独分析特定乐器的和声
   - 使用"高级"分析深度获取更详细的和弦信息

2. **优化MIDI转换结果**：
   - 转换前使用Audacity对音频进行降噪和归一化处理
   - 吉他演奏选择"吉他"乐器类型可获得更准确的结果
   - 使用DAW的"量化"功能微调MIDI音符时序

3. **创意应用技巧**：
   - 将一首歌的和弦进行应用到另一首歌的人声上，创造新的编曲
   - 使用"移调"功能为人声添加转调效果
   - 将分离的鼓轨与新旋律结合，创造全新的歌曲

4. **性能优化**：
   - 处理大文件时关闭其他占用CPU/GPU的程序
   - 使用SSD存储可显著提高处理速度
   - 对于长音频文件，建议先切割成1-3分钟的片段进行处理

#### 常见问题与解决方案

| 问题 | 原因 | 解决方案 |
|------|------|----------|
| 和弦匹配结果不和谐 | 音频质量差或人声不清晰 | 1. 使用高质量的清唱录音<br>2. 确保背景噪音最小化<br>3. 调整人声音量使其清晰可闻 |
| 乐器转MIDI结果不准确 | 乐器复杂或混音复杂 | 1. 转换前先进行乐器分离<br>2. 提高精度设置<br>3. 使用单一乐器音频文件 |
| 处理时间过长 | 文件过大或硬件配置低 | 1. 使用GPU版本启动器<br>2. 将大文件切割成小片段<br>3. 降低精度设置 |
| 无法下载MIDI文件 | 浏览器阻止弹出窗口 | 1. 允许网站弹出窗口<br>2. 检查浏览器下载设置<br>3. 刷新页面并重新处理 |

### 2. 程序员场景

#### 适用场景
适合软件开发者、程序员、数据分析师、算法工程师等技术专业人士使用WebUI进行代码分析、优化、文档生成、bug排查和技术学习。

#### 所需准备
1. **硬件要求**：根据代码复杂度选择版本
   - 简单代码分析：使用`OllamaWebUI_CPU.exe`
   - 复杂代码优化/大文件分析：使用`OllamaWebUI_GPU.exe`或`OllamaWebUI_GPU_MEM.exe`
2. **代码文件**：准备好需要分析的代码文件（支持Python、JavaScript、Java、C++等多种语言）
3. **开发工具**：建议安装代码编辑器（如VS Code、PyCharm）用于后续代码修改
4. **环境准备**：确保已安装Ollama服务和相关模型

#### 保姆级完整工作流

### 第一步：启动WebUI（30秒完成）

1. **选择合适的启动器**：
   - 简单代码分析：使用`OllamaWebUI_CPU.exe`
   - 复杂代码优化：使用`OllamaWebUI_GPU.exe`
   - 大文件/多文件分析：使用`OllamaWebUI_GPU_MEM.exe`

2. **运行启动器**：
   - 双击下载的启动器文件（无需安装，绿色软件）
   - 首次运行可能会被杀毒软件拦截，点击"允许"或"信任"

3. **访问界面**：
   - 启动后，浏览器会自动打开，显示WebUI主界面
   - 如果未自动打开，手动访问：`http://localhost:8001`

### 第二步：代码质量评估（10分钟掌握）

对现有代码进行全面的质量评估，包括可读性、性能、安全性等方面。

```
详细步骤：
1. 点击顶部的"代码处理"选项卡
2. 在"处理类型"下拉菜单中选择"代码质量评估"
3. 点击"选择文件"按钮，上传您的代码文件
4. 或直接在代码编辑区粘贴代码片段
5. 在"评估维度"中选择需要评估的方面：
   - 可读性：代码结构、命名规范、注释质量
   - 性能：时间复杂度、空间复杂度、潜在瓶颈
   - 安全性：漏洞、注入风险、权限问题
   - 可维护性：模块化、耦合度、扩展性
6. 点击"处理代码"按钮，等待处理完成

预期结果：
- 生成详细的代码质量报告
- 指出代码中的问题和改进建议
- 提供可读性评分和性能分析
- 支持下载完整的评估报告
```

### 第三步：代码优化建议（15分钟精通）

获取专业的代码优化建议，提高代码性能和可读性。

```
详细步骤：
1. 点击顶部的"代码处理"选项卡
2. 在"处理类型"下拉菜单中选择"代码优化建议"
3. 上传需要优化的代码文件
4. 在"优化重点"中选择：
   - 性能优化：减少执行时间和资源消耗
   - 可读性优化：提高代码清晰度和可维护性
   - 安全性优化：修复潜在的安全漏洞
   - 内存优化：减少内存占用和泄漏风险
5. 点击"处理代码"按钮，等待处理完成

预期结果：
- 提供具体的优化建议和修改方案
- 展示优化前后的性能对比
- 解释优化原理和技术细节
- 支持直接查看优化后的代码示例
```

### 第四步：API文档生成（10分钟入门）

自动生成专业的API文档，提高代码的可维护性和使用体验。

```
详细步骤：
1. 点击顶部的"代码处理"选项卡
2. 在"处理类型"下拉菜单中选择"API文档生成"
3. 上传包含API的代码文件
4. 在"文档格式"中选择：
   - Markdown：适合GitHub等平台
   - HTML：适合网站展示
   - JSON：适合自动化工具处理
5. 在"文档级别"中选择：
   - 基础：只包含函数签名和参数说明
   - 详细：包含使用示例和返回值说明
6. 点击"处理代码"按钮，等待处理完成

预期结果：
- 生成结构化的API文档
- 包含函数/类的详细说明
- 提供使用示例和参数说明
- 支持下载完整的文档文件
```

### 第五步：Bug排查与修复（20分钟专业应用）

分析代码中的Bug并提供修复方案，提高代码的稳定性。

```
详细步骤：
1. 点击顶部的"代码处理"选项卡
2. 在"处理类型"下拉菜单中选择"Bug排查与修复"
3. 上传有问题的代码文件
4. 在输入框中描述Bug的现象和复现步骤
5. 点击"处理代码"按钮，等待处理完成

预期结果：
- 定位代码中的Bug位置
- 分析Bug产生的原因
- 提供具体的修复方案
- 支持下载修复后的代码文件
```

### 第六步：结果应用（开发集成）

将WebUI生成的结果应用到实际开发中：

1. **应用优化建议**：
   - 打开您的代码编辑器（如VS Code）
   - 根据WebUI提供的优化建议修改代码
   - 运行测试验证优化效果

2. **使用生成的文档**：
   - 将生成的API文档整合到项目中
   - 更新README或项目文档
   - 与团队成员共享文档

3. **修复Bug**：
   - 按照WebUI提供的修复方案修改代码
   - 运行单元测试确保Bug已修复
   - 进行回归测试确保没有引入新问题

#### 程序员高级技巧

1. **提高代码分析准确性**：
   - 对于大型项目，先分析核心模块，再逐步扩展
   - 使用多个模型进行交叉验证分析结果
   - 提供完整的代码上下文以获得更准确的分析

2. **优化分析效率**：
   - 对大文件进行分割，分块分析
   - 使用GPU版本加速大文件处理
   - 关闭其他占用资源的程序以提高处理速度

3. **多语言代码分析**：
   - 针对不同语言选择合适的模型（如code llama用于代码分析）
   - 使用"代码转换"功能在不同语言间进行代码转换
   - 利用多语言支持进行跨语言项目分析

4. **性能优化高级技巧**：
   - 结合`cProfile`日志进行更深入的性能分析
   - 使用"算法复杂度分析"功能优化核心算法
   - 根据硬件环境调整代码优化策略

#### 常见问题与解决方案

| 问题 | 原因 | 解决方案 |
|------|------|----------|
| 代码分析结果不准确 | 代码上下文不完整 | 1. 提供完整的代码文件<br>2. 描述代码的运行环境和依赖<br>3. 选择适合的模型 |
| 处理大文件时超时 | 文件过大或硬件配置不足 | 1. 将大文件分割成多个小文件<br>2. 使用GPU版本启动器<br>3. 调整`config.json`中的超时设置 |
| 生成的文档不完整 | 代码注释不足或结构不清晰 | 1. 添加必要的代码注释<br>2. 优化代码结构<br>3. 选择"详细"文档级别 |
| Bug定位不准确 | Bug描述不详细或复现步骤不清晰 | 1. 详细描述Bug现象<br>2. 提供完整的错误信息和日志<br>3. 提供最小化复现示例 |

### 3. 普通用户场景

#### 适用场景
适合日常用户、学生、教师等非专业人士使用WebUI进行学习辅助、信息查询、内容创作、生活助手等多种用途。

#### 所需准备
1. **硬件要求**：普通配置即可使用
   - 基础使用：`OllamaWebUI_CPU.exe`
   - 多媒体处理：`OllamaWebUI_GPU.exe`
2. **网络连接**：稳定的网络连接用于下载模型和更新
3. **浏览器**：现代浏览器（Chrome、Edge、Firefox等）
4. **存储空间**：建议预留至少2GB存储空间用于临时文件

#### 保姆级完整工作流

### 第一步：启动WebUI（30秒完成）

1. **选择合适的启动器**：
   - 基础使用（文字对话）：`OllamaWebUI_CPU.exe`
   - 多媒体处理（图片/音频）：`OllamaWebUI_GPU.exe`

2. **运行启动器**：
   - 双击下载的启动器文件（无需安装，绿色软件）
   - 首次运行可能会被杀毒软件拦截，点击"允许"或"信任"

3. **访问界面**：
   - 启动后，浏览器会自动打开，显示WebUI主界面
   - 如果未自动打开，手动访问：`http://localhost:8001`

### 第二步：文字对话（5分钟掌握）

与AI进行自然语言对话，获取各种信息和帮助。

```
详细步骤：
1. 点击顶部的"对话"选项卡
2. 在"模型选择"中选择合适的模型（推荐使用llama3）
3. 在输入框中输入您的问题或请求
4. 点击"发送"按钮或按`Ctrl+Enter`
5. 等待AI回复并查看结果

常见使用场景：
- 学习辅助："请解释一下量子力学的基本概念"
- 生活助手："今天的天气怎么样？"
- 内容创作："帮我写一首关于春天的诗歌"
- 信息查询："中国的首都是哪里？"
- 问题解答："如何学习Python编程？"

预期结果：
- 获得自然、流畅的回答
- 支持多轮对话和上下文理解
- 可查看对话历史记录
- 支持清空对话和重新开始
```

### 第三步：内容创作（15分钟精通）

使用AI辅助进行各种内容创作，如文章、邮件、报告等。

```
详细步骤：
1. 点击顶部的"对话"选项卡
2. 选择合适的模型
3. 在输入框中详细描述您的创作需求，包括：
   - 内容类型（文章、邮件、报告等）
   - 主题和要点
   - 风格和语气（正式、随意、幽默等）
   - 目标受众
4. 点击"发送"按钮，等待AI生成内容
5. 可以根据需要要求AI修改或扩展内容

创作示例：
- "帮我写一封请假邮件，理由是生病，需要请三天假"
- "写一篇关于环保的短文，适合中学生阅读"
- "帮我制定一个一周健身计划，适合初学者"
- "写一份产品介绍，突出产品的创新特点"

预期结果：
- 生成符合要求的原创内容
- 支持多次修改和优化
- 内容结构清晰，逻辑严谨
- 可直接复制使用或进一步编辑
```

### 第四步：图片分析（10分钟入门）

上传图片并获取AI的分析结果，如内容识别、物体检测、场景描述等。

```
详细步骤：
1. 点击顶部的"图片处理"选项卡
2. 在"处理类型"下拉菜单中选择"图片分析"
3. 点击"选择图片"按钮，上传您的图片
4. 或直接拖拽图片到上传区域
5. 点击"处理图片"按钮，等待处理完成

常见使用场景：
- 内容识别："这张图片里有什么？"
- 物体检测："图片中有哪些动物？"
- 场景描述："描述这张图片的内容"
- 文字提取："提取图片中的文字"

预期结果：
- 详细的图片分析结果
- 物体识别和分类
- 场景描述和情感分析
- 支持下载分析报告
```

### 第五步：学习辅助（20分钟专业应用）

利用AI进行学习辅助，如知识点解释、题目解答、学习计划制定等。

```
详细步骤：
1. 点击顶部的"对话"选项卡
2. 选择适合学习的模型（如llama3、mistral等）
3. 在输入框中描述您的学习需求：
   - 知识点解释："请解释一下光合作用的过程"
   - 题目解答："帮我解这道数学题：2x + 5 = 15"
   - 学习计划："帮我制定一个一个月的英语学习计划"
   - 概念对比："解释一下AI和机器学习的区别"
4. 点击"发送"按钮，等待AI回复
5. 可以进一步提问以深化理解

预期结果：
- 清晰易懂的知识点解释
- 详细的题目解答步骤
- 个性化的学习计划
- 支持多轮问答和深入讨论
```

### 第六步：日常生活助手（5分钟轻松使用）

使用AI作为日常生活助手，解决各种生活中的问题。

```
详细步骤：
1. 点击顶部的"对话"选项卡
2. 选择合适的模型
3. 在输入框中提出您的生活问题：
   - 食谱推荐："帮我推荐一个简单的家常菜食谱"
   - 旅行建议："去北京旅游有哪些必去的景点？"
   - 购物建议："买笔记本电脑需要注意什么？"
   - 健康咨询："如何缓解头痛？"
4. 点击"发送"按钮，等待AI回复

预期结果：
- 实用的生活建议和解决方案
- 详细的步骤和说明
- 个性化的推荐内容
- 可直接应用的实用信息
```

#### 普通用户高级技巧

1. **提高对话质量**：
   - 问题描述要详细明确
   - 提供必要的背景信息
   - 可以使用"请详细说明"等关键词获得更详细的回答

2. **内容创作技巧**：
   - 明确说明内容的用途和目标受众
   - 提供具体的要点和要求
   - 可以要求AI生成多个版本供选择

3. **学习效率提升**：
   - 将复杂问题分解为多个小问题
   - 使用对比和举例的方式提问
   - 定期复习和巩固所学内容

4. **隐私保护**：
   - 不要在对话中透露个人敏感信息
   - 定期清理对话历史记录
   - 注意保护个人隐私和数据安全

#### 常见问题与解决方案

| 问题 | 原因 | 解决方案 |
|------|------|----------|
| 回答不准确 | 问题描述不清晰或模型选择不当 | 1. 明确、具体地描述问题<br>2. 选择适合的模型<br>3. 提供必要的背景信息 |
| 对话响应慢 | 网络不稳定或模型较大 | 1. 检查网络连接<br>2. 选择较小的模型<br>3. 关闭其他占用资源的程序 |
| 无法上传文件 | 文件格式不支持或大小超过限制 | 1. 检查文件格式是否支持<br>2. 压缩文件大小<br>3. 分割大文件 |
| 浏览器崩溃 | 浏览器版本过低或缓存问题 | 1. 更新浏览器到最新版本<br>2. 清理浏览器缓存<br>3. 尝试使用其他浏览器 |

#### 创意案例分享

1. **快速Demo创作**：
   - 录制30秒清唱 → 人声配和弦 → 下载MIDI → 导入FL Studio → 添加鼓和贝斯 → 完成Demo

2. **学习经典歌曲**：
   - 上传经典歌曲 → 和弦分析 → 下载和弦谱 → 学习和声结构 → 应用到自己的创作中

3. **采样重构**：
   - 上传老歌 → 乐器分离 → 提取鼓和贝斯轨 → 与新旋律结合 → 创造全新歌曲

4. **编曲灵感**：
   - 输入简单旋律 → 人声配和弦 → 尝试不同风格 → 选择喜欢的版本 → 扩展为完整编曲

##### 混音/母带分析
1. 点击"音频处理"选项卡
2. 在"处理类型"中选择"混音/母带分析"
3. 上传混音或母带音频文件
4. 在输入框中描述您的需求（如"请帮我分析这个混音，指出改进空间"）
5. 点击"处理音频"按钮
6. 处理完成后，查看专业的分析和改进建议

#### 2. 图片处理功能

1. 点击"图片处理"选项卡
2. 上传图片文件
3. 在输入框中描述您的分析需求（如"分析图片内容"、"提取图片中的文字"等）
4. 点击"处理图片"按钮
5. 查看分析结果

#### 3. 代码处理功能

1. 点击"代码处理"选项卡
2. 上传代码文件或直接在文本框中输入代码
3. 在输入框中描述您的需求（如"分析函数功能"、"评估代码质量"、"优化代码"等）
4. 点击"处理代码"按钮
5. 查看分析结果

#### 4. 文字对话界面

1. 点击"对话"选项卡
2. 选择合适的模型
3. 在输入框中输入您的问题或请求
4. 点击"发送"按钮
5. 查看模型的回答

#### 5. 实时任务显示

WebUI会在右侧面板实时显示当前进行中的任务，包括：
- 任务类型（音频/图片/代码处理）
- 任务状态（处理中/完成/失败）
- 处理进度
- 预计剩余时间

### WebUI界面操作指南

#### 实际操作示例

##### 音频处理示例：和弦分析

1. **启动WebUI**：
   ```
   双击 OllamaWebUI_GPU.exe → 等待浏览器自动打开 → 进入音频处理选项卡
   ```

2. **选择模型**：
   - 在左侧面板的"模型选择"下拉菜单中选择"llama3:70b"
   - 或输入自定义模型名称

3. **上传音频**：
   - 点击"选择音频文件"按钮，选择本地的.mp3文件
   - 或直接拖拽文件到上传区域

4. **设置参数**：
   ```
   处理类型：和弦分析
   分析精度：高
   输出格式：和弦进行 + 调性分析
   ```

5. **开始处理**：
   - 点击"处理音频"按钮
   - 在右侧任务列表中查看实时进度（预计完成时间：1-2分钟）

6. **查看结果**：
   - 处理完成后，在右侧面板查看：
     - 和弦进行图表
     - 调性识别结果
     - 和声结构分析
   - 点击"下载结果"按钮保存分析报告

##### 代码处理示例：代码优化

1. **进入代码处理选项卡**：
   - 点击顶部导航栏的"代码处理"选项卡

2. **输入/上传代码**：
   ```python
   # 原始代码
   def fibonacci(n):
       if n <= 0:
           return []
       elif n == 1:
           return [0]
       elif n == 2:
           return [0, 1]
       else:
           fib = [0, 1]
           for i in range(2, n):
               fib.append(fib[i-1] + fib[i-2])
           return fib
   ```

3. **描述需求**：
   ```
   请优化这段斐波那契数列代码，提高运行效率
   ```

4. **处理代码**：
   - 点击"处理代码"按钮
   - 等待处理完成（预计：30秒-1分钟）

5. **查看优化结果**：
   ```python
   # 优化后的代码
   def fibonacci(n):
       if n <= 0:
           return []
       elif n == 1:
           return [0]
       
       fib = [0] * n
       fib[1] = 1
       for i in range(2, n):
           fib[i] = fib[i-1] + fib[i-2]
       return fib
   ```

#### 快捷键和快捷操作

##### 通用快捷键

| 快捷键 | 功能 |
|-------|------|
| `Ctrl + Enter` | 发送消息/开始处理 |
| `Ctrl + K` | 清空输入框 |
| `Ctrl + L` | 切换语言 |
| `Ctrl + Shift + M` | 打开模型选择面板 |
| `Esc` | 关闭当前弹出窗口 |

##### 音频处理快捷操作

| 快捷键 | 功能 |
|-------|------|
| `Ctrl + 1` | 选择和弦分析 |
| `Ctrl + 2` | 选择人声配和弦 |
| `Ctrl + 3` | 选择乐器转MIDI |
| `Ctrl + 4` | 选择乐器分离 |

##### 图片处理快捷操作

| 快捷键 | 功能 |
|-------|------|
| `Ctrl + O` | 打开图片文件 |
| `Ctrl + S` | 保存分析结果 |
| `Ctrl + R` | 刷新预览 |

##### 代码处理快捷操作

| 快捷键 | 功能 |
|-------|------|
| `Ctrl + A` | 全选代码 |
| `Ctrl + F` | 搜索代码 |
| `Ctrl + /` | 注释/取消注释 |

#### 界面个性化设置

1. **主题切换**：
   - 点击右上角"设置"按钮
   - 在"外观"选项中选择"浅色"或"深色"主题

2. **字体大小调整**：
   - 在"设置"面板中选择"字体大小"
   - 调整为"小"、"中"、"大"或自定义值

3. **语言设置**：
   - 在"设置"面板中选择"语言"
   - 支持中文、英文、日文等多种语言

4. **快捷键自定义**：
   - 在"设置"面板中选择"快捷键"
   - 点击对应功能的快捷键组合进行修改

### 用户场景教程

#### 场景一：音乐创作者

##### 适用场景
适合音乐制作人、作曲家、编曲师、歌手等音乐从业者使用WebUI进行音乐创作辅助、音频分析、MIDI制作和歌曲重编。

##### 所需准备
1. **硬件要求**：推荐使用GPU版本启动器（OllamaWebUI_GPU.exe），需NVIDIA GPU（CUDA 11.0+）
2. **音频文件**：准备需要分析或处理的音频文件（支持.mp3/.wav/.flac格式，建议采样率44.1kHz）
3. **DAW软件**：推荐安装DAW软件（如Cubase、FL Studio、Logic Pro、Ableton Live）用于后续编辑
4. **存储空间**：建议预留至少5GB存储空间用于临时文件处理

##### 保姆级完整工作流

### 第一步：启动WebUI（30秒完成）

1. **选择合适的启动器**：
   - 如果您的电脑有NVIDIA显卡（GTX 1660及以上）：使用`OllamaWebUI_GPU.exe`
   - 如果您的电脑没有GPU：使用`OllamaWebUI_CPU.exe`
   - 如果您的电脑配置很高（8GB+ RAM + 高端GPU）：使用`OllamaWebUI_GPU_MEM.exe`

2. **运行启动器**：
   - 直接双击下载好的启动器文件（无需安装，绿色软件）
   - 首次运行可能会被杀毒软件拦截，点击"允许"或"信任"即可

3. **访问界面**：
   - 启动后会自动打开浏览器，显示WebUI主界面
   - 如果未自动打开，手动访问：`http://localhost:8001`

### 第二步：人声配和弦（10分钟掌握）

这是音乐创作者最常用的功能，可以为您的人声自动生成和谐的和弦进行。

```
详细步骤：
1. 点击顶部的"音频处理"选项卡
2. 在"处理类型"下拉菜单中选择"人声配和弦"
3. 点击"选择文件"按钮，上传您的人声音频文件（建议1-3分钟的清唱片段）
4. 在"风格选择"中选择适合的风格：
   - 流行：适合现代流行歌曲
   - 爵士：适合复杂和声的爵士风格
   - 古典：适合优雅的古典音乐风格
   - 摇滚：适合强劲的摇滚风格
5. 在"伴奏类型"中选择您想要的伴奏乐器：
   - 钢琴：优雅的钢琴伴奏
   - 吉他：温暖的吉他伴奏
   - 乐队：完整的乐队伴奏
6. 点击"处理音频"按钮，等待处理完成

预期结果：
- 生成与您人声完美匹配的和弦进行
- 提供多种和弦进行变体供您选择
- 可以播放试听不同风格的伴奏
- 可下载MIDI格式的和弦文件，直接导入DAW
```

### 第三步：乐器转MIDI（15分钟精通）

将真实乐器演奏转换为MIDI格式，方便您在DAW中进行编辑和修改。

```
详细步骤：
1. 点击顶部的"音频处理"选项卡
2. 在"处理类型"下拉菜单中选择"乐器转MIDI"
3. 点击"选择文件"按钮，上传您的乐器独奏音频（如吉他solo、钢琴演奏）
4. 在"乐器类型"中选择您上传的乐器：
   - 吉他：处理吉他演奏
   - 钢琴：处理钢琴演奏
   - 弦乐：处理小提琴等弦乐
   - 其他：处理其他乐器
5. 在"精度设置"中选择：
   - 低：处理速度快，适合简单旋律
   - 中：平衡速度和精度
   - 高：精度最高，适合复杂演奏（处理时间较长）
6. 点击"处理音频"按钮，等待处理完成

预期结果：
- 将真实乐器演奏转换为精确的MIDI音符
- 保留原始演奏的力度变化和表情
- 自动识别音符的起始时间和持续时间
- 可下载MIDI文件，直接导入DAW进行编辑
```

### 第四步：和弦分析（5分钟快速上手）

分析现有歌曲的和弦进行，学习优秀作品的和声结构。

```
详细步骤：
1. 点击顶部的"音频处理"选项卡
2. 在"处理类型"下拉菜单中选择"和弦分析"
3. 点击"选择文件"按钮，上传您想要分析的歌曲
4. 在"分析深度"中选择：
   - 基础：仅分析主要和弦
   - 高级：分析和弦转位和扩展和弦
5. 点击"处理音频"按钮，等待处理完成

预期结果：
- 生成完整的和弦进行图谱
- 显示每小节的和弦名称（如Cmaj7、Am7）
- 识别歌曲的调式和拍号
- 可下载和弦谱PDF用于学习
```

### 第五步：乐器分离（20分钟专业级应用）

将完整歌曲分离为独立的乐器轨道，方便进行重新编曲或采样。

```
详细步骤：
1. 点击顶部的"音频处理"选项卡
2. 在"处理类型"下拉菜单中选择"乐器分离"
3. 点击"选择文件"按钮，上传您想要分离的完整歌曲
4. 在"分离选项"中选择您需要的轨道：
   - 人声
   - 鼓
   - 贝斯
   - 吉他
   - 钢琴
   - 其他乐器
5. 点击"处理音频"按钮，等待处理完成（大型文件可能需要较长时间）

预期结果：
- 生成多个独立的音频轨道文件
- 各轨道保持原始音质和细节
- 可单独下载每个轨道
- 可用于重新编曲、混音或采样
```

### 第六步：结果应用（DAW集成）

将WebUI生成的结果导入到DAW软件中进行后续编辑：

1. **导入MIDI文件**：
   - 打开您的DAW软件（如FL Studio）
   - 选择"文件" → "导入" → "MIDI文件"
   - 选择从WebUI下载的MIDI文件
   - 为MIDI轨道分配合适的音色

2. **使用分离的音频**：
   - 将分离的音频轨道导入到DAW
   - 重新调整各轨道的音量平衡
   - 添加效果器（混响、压缩、EQ等）

3. **创作完成**：
   - 根据需要修改和弦进行或旋律
   - 添加其他乐器轨道丰富编曲
   - 导出最终的音频文件

##### 音乐创作者高级技巧

1. **提升和弦分析精度**：
   - 对于复杂的音乐，先进行乐器分离，再单独分析某一乐器的和声
   - 使用"高级"分析深度获得更详细的和弦信息

2. **优化MIDI转换结果**：
   - 转换前使用Audacity对音频进行降噪和归一化处理
   - 对于吉他演奏，选择"吉他"乐器类型可获得更准确的结果
   - 使用DAW的"量化"功能微调MIDI音符的时间

3. **创意应用技巧**：
   - 将一首歌的和弦进行应用到另一首歌的人声上，创造新的编曲
   - 使用"调性偏移"功能，为人声添加转调效果
   - 将分离的鼓轨道与新的旋律结合，创造全新的歌曲

4. **性能优化**：
   - 处理大型文件时，关闭其他占用CPU/GPU的程序
   - 使用SSD存储可以显著提升处理速度
   - 对于长音频文件，建议先裁剪成1-3分钟的片段进行处理

##### 常见问题与解决方案

| 问题 | 原因 | 解决方案 |
|-----|-----|--------|
| 人声配和弦结果不和谐 | 音频质量差或人声不清晰 | 1. 使用高质量的清唱录音<br>2. 确保背景噪音尽可能小<br>3. 调整人声音量使其清晰可闻 |
| 乐器转MIDI结果不准确 | 乐器复杂或混音复杂 | 1. 先进行乐器分离再转换<br>2. 提高精度设置<br>3. 使用单一乐器的音频文件 |
| 处理时间过长 | 文件过大或硬件配置低 | 1. 使用GPU版本启动器<br>2. 将大文件裁剪成小片段<br>3. 降低精度设置 |
| 无法下载MIDI文件 | 浏览器阻止弹出窗口 | 1. 允许网站弹出窗口<br>2. 检查浏览器下载设置<br>3. 刷新页面重新处理 |

##### 创意案例分享

1. **快速创作Demo**：
   - 录制30秒清唱 → 人声配和弦 → 下载MIDI → 导入FL Studio → 添加鼓点和贝斯 → 完成Demo

2. **学习经典歌曲**：
   - 上传经典歌曲 → 和弦分析 → 下载和弦谱 → 学习和声结构 → 应用到自己的创作中

3. **采样重构**：
   - 上传老歌 → 乐器分离 → 提取鼓点和贝斯 → 与新的旋律结合 → 创造全新作品

4. **编曲灵感获取**：
   - 输入简单旋律 → 人声配和弦 → 尝试不同风格 → 选择最喜欢的版本 → 扩展为完整编曲

#### 场景二：程序员

##### 适用场景
适合软件开发者、数据科学家、算法工程师等技术人员使用WebUI进行代码分析、性能优化、文档自动生成、bug定位与修复、架构设计咨询等开发相关任务。

##### 所需准备
1. **硬件要求**：CPU版本启动器（OllamaWebUI_CPU.exe）即可满足基本需求；若处理大型代码库，建议使用GPU+内存优化版（OllamaWebUI_GPU_MEM.exe）
2. **代码文件**：准备需要分析或优化的代码文件（支持Python、JavaScript、Java、C++、Go、Rust等20+种编程语言）
3. **开发环境**：可选，用于测试优化后的代码（如VS Code、PyCharm等IDE）
4. **错误信息**：若进行bug排查，建议准备完整的错误堆栈信息

##### 完整工作流（保姆级教程）

1. **启动WebUI**：
   - 从官网或GitHub Releases下载`OllamaWebUI_CPU.exe`
   - 双击运行，看到命令行窗口弹出（显示"Flask app running on http://127.0.0.1:8001"）
   - 浏览器会自动打开WebUI界面（若未自动打开，手动访问http://localhost:8001）

2. **代码质量全面评估**：
   ```
   步骤：
   1. 点击顶部导航栏的"代码处理"选项卡
   2. 点击"选择文件"按钮，上传需要分析的Python代码文件（如`main.py`）
   3. 在"需求描述"框中输入："请从可读性、性能、安全性、可维护性四个维度评估这段代码，并给出具体的改进建议"
   4. 点击"高级设置"，选择模型为"CodeLlama-7b"，调整温度为0.3（降低随机性）
   5. 点击"处理代码"按钮
   
   预期结果：
   - 代码质量评分（0-10分制）
   - 四大维度的详细分析报告
   - 每处问题的具体行号和修复建议
   - 优化后的完整代码示例
   ```

3. **性能瓶颈深度分析与优化**：
   ```
   步骤：
   1. 在"代码处理"选项卡中，上传性能不佳的代码文件
   2. 同时上传该代码的运行时性能日志（如Python的`cProfile`输出）
   3. 输入需求："请结合性能日志，找出代码中的性能瓶颈，并提供针对性的优化方案，包括算法优化和代码结构调整"
   4. 点击"处理代码"
   
   预期结果：
   - 性能热点可视化图表（耗时最长的函数和代码行）
   - 算法复杂度分析（如O(n²)优化为O(n log n)）
   - 内存使用优化建议
   - 优化前后的性能对比数据
   - 完全优化后的代码实现
   ```

4. **自动化API文档生成**：
   ```
   步骤：
   1. 上传完整的Python模块文件（如`utils.py`）
   2. 输入需求："请为这个模块生成符合Google风格的API文档，包括模块说明、函数参数、返回值、异常处理、代码示例"
   3. 点击"处理代码"
   
   预期结果：
   - 完整的Markdown格式API文档
   - 每个函数的详细说明
   - 可直接运行的代码示例
   - 类型提示和异常说明
   ```

5. **复杂Bug定位与修复**：
   ```
   步骤：
   1. 上传有bug的代码文件
   2. 在"需求描述"中粘贴完整的错误堆栈信息
   3. 补充说明："请找出并修复这个bug，解释bug产生的原因，并提供测试用例验证修复效果"
   4. 点击"处理代码"
   
   预期结果：
   - 精确的bug位置定位（文件名和行号）
   - bug产生的根本原因分析
   - 修复后的代码实现
   - 详细的修复思路说明
   - 用于验证的测试用例
   ```

6. **架构设计咨询与重构建议**：
   ```
   步骤：
   1. 上传多个相关的代码文件（或压缩后的代码目录）
   2. 输入需求："请分析这个项目的架构设计，评估其合理性，并提供重构建议以提高可扩展性和可维护性"
   3. 选择"DeepSeek-Coder-15b"模型以获得更专业的架构建议
   4. 点击"处理代码"
   
   预期结果：
   - 现有架构的优势和劣势分析
   - 具体的重构方案（如模块化拆分、设计模式应用）
   - 重构后的代码结构示意图
   - 实施重构的步骤建议
   ```

7. **结果应用与验证**：
   - 将优化后的代码复制到IDE中进行测试
   - 使用生成的API文档更新项目README或Wiki
   - 按照修复建议解决bug并运行测试用例验证
   - 对于架构重构，制定详细的实施计划并逐步执行

##### 程序员高级技巧
1. **大型代码库处理**：
   - 将代码库按模块压缩为ZIP文件上传，WebUI会自动解压并分析
   - 使用"批量处理"功能，同时分析多个相关文件
   - 对于超过10000行的代码，先使用"代码摘要"功能生成概述

2. **模型选择策略**：
   - 代码质量评估：CodeLlama-7b
   - 性能优化：DeepSeek-Coder-15b
   - 架构设计：StarCoder-16b
   - 多语言支持：WizardCoder-15b

3. **高效提问技巧**：
   - 具体明确："请优化第12-25行的循环性能"而非"代码太慢了"
   - 提供上下文：说明代码的应用场景和约束条件
   - 使用专业术语：如"时间复杂度"、"空间复杂度"、"内存泄漏"

4. **快捷键操作**：
   - Ctrl+1：快速切换到代码处理选项卡
   - Ctrl+Enter：快速提交代码处理请求
   - Ctrl+S：保存当前的代码分析结果
   - Ctrl+L：清空当前输入

##### 常见问题与解决方案
1. **问题**：上传大型代码文件时提示"文件过大"
   **解决方案**：打开`config.json`文件，将`"max_file_size"`从默认的100MB修改为500MB

2. **问题**：代码分析结果不准确
   **解决方案**：
   - 选择更专业的代码模型（如CodeLlama）
   - 分段处理大型代码文件
   - 提供更详细的需求描述

3. **问题**：处理代码时WebUI卡顿
   **解决方案**：
   - 关闭其他占用CPU/GPU的程序
   - 使用GPU优化版启动器
   - 在`config.json`中降低`"max_concurrent"`参数（默认5，改为2-3）

4. **问题**：无法识别某些编程语言
   **解决方案**：在需求描述中明确指定编程语言，如"这是一段Rust代码，请分析其性能"

##### 实际应用案例
**案例1：优化Python数据处理脚本**
- 原始代码：处理100万行CSV文件需要15分钟
- 使用WebUI分析后：识别出嵌套循环和低效IO操作
- 优化后：处理时间缩短至45秒（性能提升20倍）

**案例2：修复Java Web应用bug**
- 问题：用户登录后偶尔出现NullPointerException
- 使用WebUI分析：定位到Session管理模块的并发问题
- 修复：添加线程安全的Session管理机制
- 结果：bug彻底解决，系统稳定性提升95%

**案例3：生成API文档**
- 原始：手动编写100个函数的文档需要2天
- 使用WebUI：自动生成符合Google风格的完整文档，仅需15分钟
- 节省时间：95%的文档编写工作

#### 场景三：普通用户

##### 适用场景
适合所有非专业用户使用WebUI解决日常问题、获取知识信息、进行趣味对话、图片分析、文字创作、旅行规划、健康咨询、学习辅助等多种生活和学习场景。

##### 所需准备
1. **硬件要求**：根据电脑配置选择合适的启动器版本
   - 无独立显卡：选择`OllamaWebUI_CPU.exe`
   - 有NVIDIA独立显卡：选择`OllamaWebUI_GPU.exe`
   - 高配置电脑（16GB+内存）：选择`OllamaWebUI_GPU_MEM.exe`
2. **图片文件**：可选，用于图片分析、识别等功能（支持JPG、PNG、BMP格式）
3. **网络连接**：首次使用需要连接互联网下载初始模型（约2-10GB）
4. **浏览器**：推荐使用Chrome、Edge、Firefox等现代浏览器

##### 完整工作流（保姆级教程）

1. **启动WebUI（首次使用）**：
   ```
   步骤：
   1. 从官网下载适合自己电脑的启动器版本（如`OllamaWebUI_CPU.exe`）
   2. 将下载的文件保存到桌面，双击运行
   3. 看到黑色命令行窗口弹出，显示"正在启动Flask服务器..."
   4. 等待约30秒-1分钟，浏览器会自动打开WebUI界面
   5. 首次使用会自动下载默认模型（llama3），请耐心等待下载完成
   ```

2. **日常问题解决（保姆级）**：
   ```
   步骤：
   1. 在WebUI界面中，确保当前在"对话"选项卡
   2. 在模型选择下拉框中选择"llama3"（适合日常对话）
   3. 在输入框中输入："我想做一道简单的家常菜，需要准备什么材料？"
   4. 点击右侧的"发送"按钮（或按Enter键）
   
   预期结果：
   - 推荐3-5道简单家常菜（如西红柿炒鸡蛋、宫保鸡丁等）
   - 每道菜的详细材料清单
   - 步骤清晰的制作方法
   - 烹饪技巧和注意事项
   ```

3. **知识学习与辅导**：
   ```
   步骤：
   1. 切换到"对话"选项卡
   2. 输入："请用简单易懂的方式解释什么是量子力学，适合中学生理解"
   3. 点击"发送"
   
   预期结果：
   - 用比喻和生活例子解释量子力学的基本概念
   - 避免复杂公式和专业术语
   - 介绍量子力学在生活中的应用（如手机芯片、GPS等）
   - 推荐适合进一步学习的资源
   ```

4. **图片智能分析**：
   ```
   步骤：
   1. 点击顶部导航栏的"图片处理"选项卡
   2. 点击"选择图片"按钮，上传一张旅游时拍摄的风景照片
   3. 在"需求描述"框中输入："请描述这张图片的内容，并猜测这可能是哪里的风景"
   4. 点击"处理图片"按钮
   
   预期结果：
   - 图片内容的详细描述（如"蓝天白云下的雪山湖泊，湖边有茂密的森林"）
   - 识别出的物体和场景（如"雪山、湖泊、针叶林、蓝天"）
   - 可能的拍摄地点推测（如"可能是瑞士阿尔卑斯山区或中国西藏纳木错"）
   - 拍摄季节和时间的猜测（如"可能拍摄于夏季的上午"）
   ```

5. **多语言翻译与交流**：
   ```
   步骤：
   1. 在"对话"选项卡中
   2. 输入："请将这段中文翻译成英文，并告诉我翻译后的句子有什么需要注意的文化差异：你吃了吗？"
   3. 点击"发送"
   
   预期结果：
   - 准确的英文翻译："Have you eaten?"
   - 解释这是中文里的问候语，相当于英文的"How are you?"
   - 说明直接翻译可能会让外国人误解为邀请吃饭
   - 提供更自然的英文问候方式
   ```

6. **创意写作与内容生成**：
   ```
   步骤：
   1. 在"对话"选项卡中
   2. 输入："请帮我写一首关于秋天的儿童诗歌，简单押韵，适合5岁孩子背诵"
   3. 点击"发送"
   
   预期结果：
   - 原创的儿童诗歌（4-6句，语言简单）
   - 包含秋天的典型元素（如落叶、果实、大雁等）
   - 押韵易记，适合儿童背诵
   - 可能的配图建议
   ```

7. **旅行规划助手**：
   ```
   步骤：
   1. 在"对话"选项卡中
   2. 输入："我计划周末去北京旅游2天，预算1000元，请帮我制定一个详细的行程计划"
   3. 点击"发送"
   
   预期结果：
   - 两天的详细行程安排（每天上午、下午、晚上的活动）
   - 推荐的必去景点和特色美食
   - 交通方式建议（地铁、公交等）
   - 预算分配参考（门票、餐饮、交通等）
   - 旅行注意事项（天气、携带物品等）
   ```

##### 普通用户实用技巧

1. **高效提问技巧**：
   - 具体明确："我想做蛋糕，需要什么材料？"而非"怎么做蛋糕？"
   - 提供细节："我家有鸡蛋和面粉，能做什么简单的甜点？"
   - 设定条件："请推荐3本适合小学生的科普书，不要太复杂"

2. **模型选择指南**：
   - 日常对话：选择"llama3"或"mistral"模型
   - 知识学习：选择"gemma"或"phi3"模型
   - 创意写作：选择"llama3"或"mixtral"模型
   - 图片分析：选择"llava"模型

3. **快捷键操作**：
   - Ctrl+1：快速切换到对话选项卡
   - Ctrl+2：快速切换到图片处理选项卡
   - Ctrl+Enter：快速发送消息
   - Ctrl+L：清空输入框
   - Ctrl+S：保存当前对话记录

4. **个性化设置**：
   - 在"设置"选项卡中，可以调整界面语言（支持中文/英文）
   - 调整"温度"参数：低温度（0.1-0.3）回答更准确，高温度（0.7-1.0）回答更有创意
   - 设置"回复长度限制"：根据需要调整回答的详细程度

##### 常见问题与解决方案

1. **问题**：启动器双击后没有反应
   **解决方案**：
   - 检查电脑是否安装了杀毒软件，可能误将启动器拦截
   - 右键点击启动器，选择"以管理员身份运行"
   - 确保电脑有足够的磁盘空间（至少需要10GB空闲空间）

2. **问题**：浏览器无法打开WebUI界面
   **解决方案**：
   - 手动在浏览器中输入地址：http://localhost:8001
   - 检查黑色命令行窗口是否还在运行（如果关闭了需要重新运行启动器）
   - 尝试更换其他浏览器（如Chrome或Edge）

3. **问题**：下载模型很慢
   **解决方案**：
   - 确保网络连接稳定
   - 关闭其他占用网络的应用（如下载工具、视频流媒体）
   - 可以尝试在网络较好的时间段（如深夜）下载

4. **问题**：回答内容不准确或不符合预期
   **解决方案**：
   - 重新组织问题，使其更清晰具体
   - 尝试选择不同的模型
   - 调整"温度"参数，降低随机性
   - 提供更多的上下文信息

5. **问题**：图片分析结果不准确
   **解决方案**：
   - 确保上传的图片清晰可见
   - 避免上传过于模糊或光线过暗的图片
   - 尝试用简单的语言描述需求，如"请识别这张图片里有什么"

##### 实际应用案例

**案例1：家庭菜谱助手**
- 用户需求：想做一道简单的家常菜，但不知道做什么
- 使用方法：在对话选项卡中提问"推荐一道简单的家常菜及做法"
- 结果：获得了西红柿炒鸡蛋的详细做法，包括材料、步骤和技巧
- 用户反馈："按照教程做的菜很好吃，步骤简单易懂"

**案例2：旅行规划神器**
- 用户需求：周末计划去上海旅游，需要行程安排
- 使用方法：提问"上海2日游详细行程，预算800元"
- 结果：获得了包含景点、美食、交通的完整行程，还贴心提示了天气情况
- 用户反馈："行程安排得很合理，节省了很多规划时间"

**案例3：孩子学习辅导**
- 用户需求：帮助孩子理解数学中的"分数"概念
- 使用方法：提问"用生活例子解释什么是分数，适合小学生"
- 结果：获得了用披萨、蛋糕等生活例子解释的分数概念
- 用户反馈："孩子一下子就理解了分数，比课本讲的更生动"

**案例4：图片记忆助手**
- 用户需求：想知道去年旅游拍的照片是在哪里拍的
- 使用方法：在图片处理选项卡上传照片，提问"这张照片可能是哪里的风景"
- 结果：准确识别出是桂林山水，并提供了相关信息
- 用户反馈："太神奇了，终于想起这是去年去桂林拍的照片"

### WebUI注意事项

1. 所有上传的文件会临时存储在`temp`目录中，处理完成后会自动清理
2. 大型文件处理可能需要较长时间，请耐心等待
3. 如果遇到连接问题，请检查Ollama服务是否正在运行
4. 推荐使用Chrome、Firefox等现代浏览器访问WebUI

### 高级功能使用技巧和最佳实践

#### 1. 音频处理高级技巧

##### 提高分析精度的方法
- **预处理优化**：使用音频编辑软件（如Audacity）对音频进行降噪、归一化处理后再上传
- **分段处理**：对于超长音频文件（>10分钟），建议分段处理以获得更准确的结果
- **模型选择**：使用音乐理论增强的模型（如`musicgen`或自定义模型）可显著提高和弦分析精度
- **参数调整**：在高级设置中增加"分析窗口大小"参数（默认2048，可调整至4096-8192）

##### 乐器转MIDI的最佳实践
- **单一乐器**：优先处理单一乐器的音频，避免复杂混音影响识别精度
- **采样率匹配**：确保音频文件采样率为44.1kHz或48kHz，这是MIDI转换的最佳采样率
- **力度保留**：在转换参数中启用"力度感应"选项，可保留原始演奏的动态信息
- **后处理**：使用DAW软件（如斯坦伯格的Cubase、FL Studio、Logic Pro）对生成的MIDI进行量化和修正

##### 人声配和弦的创意应用
- **风格融合**：尝试将不同音乐风格的和弦进行应用到人声上，创造独特效果
- **调性转换**：使用"调性偏移"参数，为人声添加转调效果
- **和声叠加**：在生成的和弦基础上，手动添加7th、9th等扩展和弦增强丰富度

#### 2. 代码处理高级技巧

##### 大型项目分析策略
- **模块化分析**：将大型项目按模块拆分，分别上传分析
- **依赖可视化**：使用"依赖分析"功能生成项目依赖关系图
- **性能瓶颈定位**：结合运行时日志一起上传，可准确定位性能问题

##### 代码优化的最佳实践
- **增量优化**：先进行整体分析，再针对高优先级问题进行优化
- **测试验证**：对优化后的代码进行单元测试，确保功能不受影响
- **跨语言迁移**：利用代码处理功能辅助将代码从一种语言迁移到另一种语言

#### 3. WebUI性能优化

##### 系统资源管理
- **任务并发控制**：在`config.json`中调整`max_concurrent`参数，避免同时运行过多任务
- **内存优化**：关闭不需要的浏览器标签页，释放系统内存
- **硬件加速**：确保浏览器启用GPU硬件加速（Chrome: 设置 → 系统 → 启用硬件加速）

##### 网络优化
- **本地模型**：优先使用本地安装的模型，避免网络延迟
- **缓存利用**：启用浏览器缓存，减少重复资源加载
- **压缩上传**：对大型文件进行压缩后上传，提高传输速度

#### 4. 高级配置示例

##### 自定义音频处理配置
```json
{
  "audio": {
    "max_file_size": 500,  // 增加最大文件大小限制到500MB
    "supported_formats": ["mp3", "wav", "flac", "ogg"],  // 添加OGG格式支持
    "analysis_precision": "high",  // 设置默认分析精度为高
    "chord_recognition": {
      "window_size": 4096,  // 增加分析窗口大小
      "confidence_threshold": 0.85  // 提高和弦识别的置信度阈值
    }
  }
}
```

##### 任务管理配置
```json
{
  "tasks": {
    "max_concurrent": 10,  // 增加最大并发任务数
    "temp_dir": "d:\\temp\\ollama",  // 自定义临时目录到D盘
    "auto_cleanup": true,  // 启用自动清理临时文件
    "cleanup_delay": 3600  // 处理完成后1小时清理临时文件
  }
}
```

### WebUI常见问题与解决方案

#### 连接与启动问题

| 问题描述 | 可能原因 | 解决方案 |
|---------|---------|---------|
| 双击EXE文件后没有反应 | 系统权限不足或文件损坏 | 1. 以管理员身份运行<br>2. 重新下载完整的EXE文件<br>3. 检查是否有杀毒软件阻止 |
| 浏览器无法打开WebUI界面 | 端口被占用或防火墙阻止 | 1. 使用`--port`参数指定新端口<br>2. 检查防火墙设置，允许WebUI访问网络<br>3. 手动在浏览器中输入地址：http://localhost:8001 |
| 提示"无法连接到Ollama服务" | Ollama服务未启动或地址错误 | 1. 运行`ollama serve`命令启动服务<br>2. 检查Ollama服务地址是否正确<br>3. 尝试重启Ollama服务 |
| WebUI界面显示空白 | 浏览器缓存问题或资源加载失败 | 1. 清除浏览器缓存并刷新页面<br>2. 尝试使用其他浏览器<br>3. 重启WebUI启动器 |

#### 文件处理问题

| 问题描述 | 可能原因 | 解决方案 |
|---------|---------|---------|
| 上传文件时提示"文件过大" | 超过了配置的文件大小限制 | 1. 修改`config.json`中的`max_file_size`参数<br>2. 压缩文件或分割成多个小文件<br>3. 使用更高配置的硬件版本 |
| 处理音频时提示"分析失败" | 音频格式不支持或文件损坏 | 1. 转换为支持的格式（.mp3/.wav）<br>2. 检查文件完整性<br>3. 尝试使用更低的分析精度 |
| 乐器转MIDI结果不准确 | 音频质量差或乐器复杂 | 1. 提高音频文件质量<br>2. 先进行乐器分离再转换<br>3. 调整分析精度参数 |
| 代码分析结果不完整 | 代码文件过大或格式错误 | 1. 分段处理大型代码文件<br>2. 检查代码格式是否正确<br>3. 使用更专业的代码模型 |

#### 性能与稳定性问题

| 问题描述 | 可能原因 | 解决方案 |
|---------|---------|---------|
| WebUI界面卡顿 | 系统资源不足或浏览器问题 | 1. 关闭其他占用资源的程序<br>2. 清除浏览器缓存<br>3. 使用GPU版本启动器 |
| 处理任务时崩溃 | 内存不足或模型问题 | 1. 关闭其他任务释放内存<br>2. 使用更低内存占用的模型<br>3. 增加系统虚拟内存 |
| 启动器自动退出 | 权限问题或系统错误 | 1. 检查`logs/webui.log`查看具体错误<br>2. 以管理员身份运行启动器<br>3. 检查系统更新和驱动程序 |
| 任务进度显示"停滞" | 处理复杂或网络问题 | 1. 耐心等待（大型文件处理时间较长）<br>2. 检查Ollama服务是否正常运行<br>3. 尝试重新提交任务 |

#### 其他问题

| 问题描述 | 可能原因 | 解决方案 |
|---------|---------|---------|
| 快捷键不生效 | 浏览器快捷键冲突 | 1. 检查浏览器设置，禁用冲突的快捷键<br>2. 在WebUI设置中自定义快捷键<br>3. 尝试使用不同的浏览器 |
| 语言显示异常 | 语言包问题或编码错误 | 1. 在设置中重新选择语言<br>2. 刷新页面或重启WebUI<br>3. 清除浏览器缓存 |
| 无法保存配置 | 权限不足或配置文件损坏 | 1. 检查`config.json`文件权限<br>2. 删除损坏的配置文件，重新生成<br>3. 以管理员身份运行启动器 |
| 杀毒软件误报 | 打包机制导致的误判 | 1. 将EXE文件添加到杀毒软件白名单<br>2. 暂时关闭杀毒软件后运行<br>3. 从官方渠道下载验证文件 |

## 更新日志
### v1.5 (2025-12-16)
- ✨ 新增多语言支持，优化用户界面
### v1.4 (2025-12-16)
- ✨ 新增WebUI启动器，支持三种硬件版本（CPU-only、GPU-only、CPU+GPU+memory）
- ✨ 新增音频处理功能：和弦分析、人声配和弦、乐器转MIDI
- ✨ 新增WebUI界面，提供音频、图片、代码处理和文字对话功能
- ✨ 新增实时任务显示功能
- ✨ 支持上传文件的深度分析
- ✨ 集成Spleeter/Demucs用于音频分离
- ✨ 集成CodeLlama/DeepSeek-Coder用于代码处理

### v1.3 (2025-10-15)
- ✨ 全面增强临时目录权限处理，增加写入权限验证机制
- ✨ 为安装目录添加多层回退机制和写入权限验证
- ✨ 改进临时文件清理的错误处理，避免权限问题
- ✨ 增强命令检查函数，支持更多命令检测方式
- ✨ 添加调试模式，输出详细的权限处理日志
- ✨ 优化错误代码说明，提供更准确的问题定位
- ✨ 更新版本信息，保持与脚本版本一致
- ✨ 进一步优化目录路径处理，确保包含空格的目录正常工作
- ✨ 增强安装目录的预检查逻辑，提高权限验证准确性
- ✨ 为所有权限错误提供详细的解决方案指导
- ✨ 优化download_file函数的目录处理逻辑

### v1.2 (2025-8-14)
- ✨ 增强临时目录处理，增加写入权限验证机制
- ✨ 增加更多备选目录（桌面、用户主目录），提高兼容性
- ✨ 优化下载工具切换逻辑，确保curl和PowerShell的可靠使用
- ✨ 更新镜像源配置，提高国内用户下载成功率
- ✨ 完善文档内容，提供更详细的技术实现说明
- ✨ 改进错误处理和日志输出，便于问题排查

### v1.1 (2025-8-12)
- ✨ 增强临时目录处理，增加更多备选目录
- ✨ 改进目录权限检查机制
- ✨ 更新文档，提供更详细的使用说明和教学
- ✨ 优化下载重试逻辑

### v1.0 (2025-8-8)
- ✨ 初始版本发布
- ✨ 支持自动依赖安装
- ✨ 智能镜像源选择
- ✨ 显卡配置检测
- ✨ 模型量化级别推荐
- ✨ 自定义模型存储路径

## 联系与支持

如果您在使用过程中遇到问题，可以通过以下方式获取帮助：
- 查看脚本输出的详细错误信息
- 检查本文档的常见问题部分
- 在 GitHub 上提交 Issue

---

**版权声明**：本脚本仅供学习和研究使用，Ollama 本身的版权归原作者所有。
