# 连析工坊 - 离线大模型运行时系统

## 项目概述
连析工坊（Lianxi Workshop）是一个跨平台的离线大模型运行时系统，旨在为用户提供本地化、安全、高效的AI大模型运行环境。该系统基于开源的Ollama项目开发，支持在多种操作系统（Windows、macOS、Android、iOS、HarmonyOS）上离线运行各种大语言模型，无需依赖外部API服务，保护用户数据隐私。

## 核心功能

### 1. 离线大模型运行
- 支持多种主流大语言模型（如Llama3、Mistral、Gemma等）
- 所有计算在本地设备完成，无需网络连接
- 保护用户数据隐私，避免数据上传到云端

### 2. 多平台支持
- **Windows**：支持Windows 7/10/11
- **macOS**：支持macOS 10.10及以上版本
- **Android**：支持Android 5.0至15.0
- **iOS**：支持iOS 9.0至18.0
- **HarmonyOS**：支持HarmonyOS 1.0至3.0（PC和手机平台）

### 3. 可爱风格WebUI
- 采用渐变背景和圆角设计，视觉效果温馨可爱
- 响应式布局，适配不同屏幕尺寸
- 平台专属字体和样式优化
- 特别提示弹窗带有卡通元素和友好交互

### 4. 多语言支持
- 自动检测用户设备语言
- 支持简体中文、繁体中文、英语、法语、德语
- 所有界面元素可动态切换语言

### 5. 权限管理
- 限制摄像头和麦克风访问权限
- 禁用不必要的后台进程，节省系统资源
- 实时监控权限状态变化

### 6. 任务跟踪系统
- 实时显示模型加载和推理进度
- 提供详细的运行日志和终端输出
- 支持多任务并行处理

## 技术架构

### 后端架构
- **语言**：Python 3.7+
- **框架**：Flask Web框架
- **核心功能**：
  - Ollama服务管理（启动、停止、状态检查）
  - 模型管理（安装、卸载、列表）
  - API接口提供（聊天、文件处理）
  - 任务跟踪和进度管理
  - 异常处理和资源清理

### 前端架构
- **技术栈**：HTML5 + CSS3 + JavaScript
- **核心功能**：
  - 响应式UI设计
  - 模型选择和加载
  - 聊天界面交互
  - 多语言切换
  - 权限管理界面
  - 实时进度显示

### 离线资源处理
- 所有图像资源转换为base64编码嵌入HTML
- 支持PWA（渐进式Web应用）
- 离线缓存机制，无需网络连接即可使用

## 使用方法

### 1. 启动程序
- 直接运行可执行文件（如`连析工坊_GPU.exe`）
- 程序会自动启动Flask服务器和Ollama服务
- 在浏览器中访问`http://localhost:8001`即可使用

### 2. 选择模型
- 在模型选择区域选择适合的模型（微型、小型、中型）
- 系统会自动加载所选模型到内存中
- 等待模型加载完成后即可开始聊天

### 3. 开始聊天
- 在聊天输入框中输入您的问题或请求
- 点击发送按钮或按回车键发送消息
- AI助手会在本地生成响应并显示在聊天记录中

### 4. 查看运行状态
- 终端窗口会显示实时运行进度和日志
- 可通过切换按钮隐藏/显示终端窗口
- 系统信息区域显示设备和浏览器信息

## 特别提示

1. **关于软件授权**：本软件基于开源Ollama项目和世界一流开源大模型开发，作者无权利收取任何费用。如果您购买了此软件，请立即联系卖家申请退款。

2. **技术参考**：本软件借鉴了公共资料和学术论文，部分难以解决的错误参考了DeepSeek R1大模型的建议。

3. **系统要求**：
   - 推荐至少4GB RAM
   - GPU加速版需要支持CUDA的NVIDIA显卡
   - CPU版支持所有现代处理器

4. **注意事项**：
   - 首次运行可能需要下载模型文件，请确保有足够的磁盘空间
   - 大型模型可能需要较长时间加载
   - 关闭程序时请使用正常退出方式，避免数据丢失

## 多语言支持

系统支持以下语言：
- 简体中文 (zh-CN)
- 繁体中文 (zh-TW)
- 英语 (en)
- 法语 (fr)
- 德语 (de)

系统会自动检测用户设备的语言设置，并切换到相应的界面语言。用户也可以在设置中手动切换语言。

## 权限管理

系统会自动管理以下权限：

1. **摄像头权限**：仅在必要时请求访问摄像头
2. **麦克风权限**：仅在语音输入功能启用时请求访问麦克风
3. **后台运行权限**：默认禁用后台同步和屏幕唤醒锁定，节省电量
4. **存储权限**：用于保存模型文件和聊天记录

用户可以在系统设置中查看和修改这些权限。

## 项目结构

```
连析工坊/
├── 2015/                  # 2015年系统版本
│   ├── Android/          # Android平台
│   ├── HarmonyOS/        # HarmonyOS平台
│   ├── iOS/              # iOS平台
│   └── macOS/            # macOS平台
├── 2025/                  # 2025年系统版本
│   ├── Android/          # Android平台
│   ├── HarmonyOS/        # HarmonyOS平台
│   ├── iOS/              # iOS平台
│   ├── macOS/            # macOS平台
│   └── Windows/          # Windows平台
├── lianxi_workshop/       # 主WebUI目录
│   ├── index.html        # 主页面
│   ├── script.js         # 前端脚本
│   ├── styles.css        # 样式文件
│   └── service-worker.js # PWA服务 worker
├── locales/               # 多语言文件
├── main.py                # Python入口文件
├── server.py              # Flask服务器
├── config.json            # 配置文件
└── 功能总结.md             # 功能总结文档
```

## 开发与调试

### 启动开发服务器
```bash
python main.py
```

### 构建可执行文件
使用PyInstaller构建不同版本：
```bash
pyinstaller OllamaWebUI_CPU.spec
pyinstaller OllamaWebUI_GPU.spec
pyinstaller OllamaWebUI_CPU_GPU_MEMORY.spec
```

### 资源转换工具
- `convert_to_base64.js`：将图像转换为base64编码
- `base64_converter.html`：在线图像转换工具

## 开源致谢

本项目基于以下开源项目和技术：

- **Ollama**：开源大模型运行时
- **Flask**：Python Web框架
- **Llama.cpp**：C++实现的大模型推理库
- **PyInstaller**：Python应用打包工具

详细的开源致谢请参考`OPEN_SOURCE_ACKNOWLEDGMENTS.md`文件。

## 联系方式

如有问题或建议，请通过以下方式联系：
- 项目GitHub仓库：[连析工坊](https://github.com/yourusername/lianxi-workshop)
- 邮箱：support@lianxi-workshop.com

## 更新日志

### 2025年12月
- 支持最新的Android 15和iOS 18系统
- 优化HarmonyOS 3.0适配
- 增加更多模型选择
- 改进UI交互体验

### 2025年10月
- 首次发布多平台版本
- 支持Windows 11和macOS 14
- 实现离线资源加载

## 许可证

本项目采用MIT许可证，详见LICENSE文件。

---

**连析工坊** - 让AI触手可及，让创造更自由！

🌸✨😊
